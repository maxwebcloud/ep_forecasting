{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           generation biomass  \\\n",
      "time                                            \n",
      "2014-12-31 23:00:00+00:00               447.0   \n",
      "2015-01-01 00:00:00+00:00               449.0   \n",
      "2015-01-01 01:00:00+00:00               448.0   \n",
      "2015-01-01 02:00:00+00:00               438.0   \n",
      "2015-01-01 03:00:00+00:00               428.0   \n",
      "...                                       ...   \n",
      "2018-12-31 18:00:00+00:00               297.0   \n",
      "2018-12-31 19:00:00+00:00               296.0   \n",
      "2018-12-31 20:00:00+00:00               292.0   \n",
      "2018-12-31 21:00:00+00:00               293.0   \n",
      "2018-12-31 22:00:00+00:00               290.0   \n",
      "\n",
      "                           generation fossil brown coal/lignite  \\\n",
      "time                                                              \n",
      "2014-12-31 23:00:00+00:00                                 329.0   \n",
      "2015-01-01 00:00:00+00:00                                 328.0   \n",
      "2015-01-01 01:00:00+00:00                                 323.0   \n",
      "2015-01-01 02:00:00+00:00                                 254.0   \n",
      "2015-01-01 03:00:00+00:00                                 187.0   \n",
      "...                                                         ...   \n",
      "2018-12-31 18:00:00+00:00                                   0.0   \n",
      "2018-12-31 19:00:00+00:00                                   0.0   \n",
      "2018-12-31 20:00:00+00:00                                   0.0   \n",
      "2018-12-31 21:00:00+00:00                                   0.0   \n",
      "2018-12-31 22:00:00+00:00                                   0.0   \n",
      "\n",
      "                           generation fossil gas  generation fossil hard coal  \\\n",
      "time                                                                            \n",
      "2014-12-31 23:00:00+00:00                 4844.0                       4821.0   \n",
      "2015-01-01 00:00:00+00:00                 5196.0                       4755.0   \n",
      "2015-01-01 01:00:00+00:00                 4857.0                       4581.0   \n",
      "2015-01-01 02:00:00+00:00                 4314.0                       4131.0   \n",
      "2015-01-01 03:00:00+00:00                 4130.0                       3840.0   \n",
      "...                                          ...                          ...   \n",
      "2018-12-31 18:00:00+00:00                 7634.0                       2628.0   \n",
      "2018-12-31 19:00:00+00:00                 7241.0                       2566.0   \n",
      "2018-12-31 20:00:00+00:00                 7025.0                       2422.0   \n",
      "2018-12-31 21:00:00+00:00                 6562.0                       2293.0   \n",
      "2018-12-31 22:00:00+00:00                 6926.0                       2166.0   \n",
      "\n",
      "                           generation fossil oil  \\\n",
      "time                                               \n",
      "2014-12-31 23:00:00+00:00                  162.0   \n",
      "2015-01-01 00:00:00+00:00                  158.0   \n",
      "2015-01-01 01:00:00+00:00                  157.0   \n",
      "2015-01-01 02:00:00+00:00                  160.0   \n",
      "2015-01-01 03:00:00+00:00                  156.0   \n",
      "...                                          ...   \n",
      "2018-12-31 18:00:00+00:00                  178.0   \n",
      "2018-12-31 19:00:00+00:00                  174.0   \n",
      "2018-12-31 20:00:00+00:00                  168.0   \n",
      "2018-12-31 21:00:00+00:00                  163.0   \n",
      "2018-12-31 22:00:00+00:00                  163.0   \n",
      "\n",
      "                           generation hydro pumped storage consumption  \\\n",
      "time                                                                     \n",
      "2014-12-31 23:00:00+00:00                                        863.0   \n",
      "2015-01-01 00:00:00+00:00                                        920.0   \n",
      "2015-01-01 01:00:00+00:00                                       1164.0   \n",
      "2015-01-01 02:00:00+00:00                                       1503.0   \n",
      "2015-01-01 03:00:00+00:00                                       1826.0   \n",
      "...                                                                ...   \n",
      "2018-12-31 18:00:00+00:00                                          1.0   \n",
      "2018-12-31 19:00:00+00:00                                          1.0   \n",
      "2018-12-31 20:00:00+00:00                                         50.0   \n",
      "2018-12-31 21:00:00+00:00                                        108.0   \n",
      "2018-12-31 22:00:00+00:00                                        108.0   \n",
      "\n",
      "                           generation hydro run-of-river and poundage  \\\n",
      "time                                                                    \n",
      "2014-12-31 23:00:00+00:00                                      1051.0   \n",
      "2015-01-01 00:00:00+00:00                                      1009.0   \n",
      "2015-01-01 01:00:00+00:00                                       973.0   \n",
      "2015-01-01 02:00:00+00:00                                       949.0   \n",
      "2015-01-01 03:00:00+00:00                                       953.0   \n",
      "...                                                               ...   \n",
      "2018-12-31 18:00:00+00:00                                      1135.0   \n",
      "2018-12-31 19:00:00+00:00                                      1172.0   \n",
      "2018-12-31 20:00:00+00:00                                      1148.0   \n",
      "2018-12-31 21:00:00+00:00                                      1128.0   \n",
      "2018-12-31 22:00:00+00:00                                      1069.0   \n",
      "\n",
      "                           generation hydro water reservoir  \\\n",
      "time                                                          \n",
      "2014-12-31 23:00:00+00:00                            1899.0   \n",
      "2015-01-01 00:00:00+00:00                            1658.0   \n",
      "2015-01-01 01:00:00+00:00                            1371.0   \n",
      "2015-01-01 02:00:00+00:00                             779.0   \n",
      "2015-01-01 03:00:00+00:00                             720.0   \n",
      "...                                                     ...   \n",
      "2018-12-31 18:00:00+00:00                            4836.0   \n",
      "2018-12-31 19:00:00+00:00                            3931.0   \n",
      "2018-12-31 20:00:00+00:00                            2831.0   \n",
      "2018-12-31 21:00:00+00:00                            2068.0   \n",
      "2018-12-31 22:00:00+00:00                            1686.0   \n",
      "\n",
      "                           generation nuclear  generation other  ...  \\\n",
      "time                                                             ...   \n",
      "2014-12-31 23:00:00+00:00              7096.0              43.0  ...   \n",
      "2015-01-01 00:00:00+00:00              7096.0              43.0  ...   \n",
      "2015-01-01 01:00:00+00:00              7099.0              43.0  ...   \n",
      "2015-01-01 02:00:00+00:00              7098.0              43.0  ...   \n",
      "2015-01-01 03:00:00+00:00              7097.0              43.0  ...   \n",
      "...                                       ...               ...  ...   \n",
      "2018-12-31 18:00:00+00:00              6073.0              63.0  ...   \n",
      "2018-12-31 19:00:00+00:00              6074.0              62.0  ...   \n",
      "2018-12-31 20:00:00+00:00              6076.0              61.0  ...   \n",
      "2018-12-31 21:00:00+00:00              6075.0              61.0  ...   \n",
      "2018-12-31 22:00:00+00:00              6075.0              61.0  ...   \n",
      "\n",
      "                           temp_Valencia  temp_min_Valencia  \\\n",
      "time                                                          \n",
      "2014-12-31 23:00:00+00:00        270.475            270.475   \n",
      "2015-01-01 00:00:00+00:00        270.475            270.475   \n",
      "2015-01-01 01:00:00+00:00        269.686            269.686   \n",
      "2015-01-01 02:00:00+00:00        269.686            269.686   \n",
      "2015-01-01 03:00:00+00:00        269.686            269.686   \n",
      "...                                  ...                ...   \n",
      "2018-12-31 18:00:00+00:00        285.640            285.150   \n",
      "2018-12-31 19:00:00+00:00        283.140            282.150   \n",
      "2018-12-31 20:00:00+00:00        281.660            281.150   \n",
      "2018-12-31 21:00:00+00:00        280.140            279.150   \n",
      "2018-12-31 22:00:00+00:00        279.140            278.150   \n",
      "\n",
      "                           temp_max_Valencia  pressure_Valencia  \\\n",
      "time                                                              \n",
      "2014-12-31 23:00:00+00:00            270.475             1001.0   \n",
      "2015-01-01 00:00:00+00:00            270.475             1001.0   \n",
      "2015-01-01 01:00:00+00:00            269.686             1002.0   \n",
      "2015-01-01 02:00:00+00:00            269.686             1002.0   \n",
      "2015-01-01 03:00:00+00:00            269.686             1002.0   \n",
      "...                                      ...                ...   \n",
      "2018-12-31 18:00:00+00:00            286.150             1028.0   \n",
      "2018-12-31 19:00:00+00:00            284.150             1029.0   \n",
      "2018-12-31 20:00:00+00:00            282.150             1029.0   \n",
      "2018-12-31 21:00:00+00:00            281.150             1029.0   \n",
      "2018-12-31 22:00:00+00:00            280.150             1029.0   \n",
      "\n",
      "                           humidity_Valencia  wind_speed_Valencia  \\\n",
      "time                                                                \n",
      "2014-12-31 23:00:00+00:00               77.0                  1.0   \n",
      "2015-01-01 00:00:00+00:00               77.0                  1.0   \n",
      "2015-01-01 01:00:00+00:00               78.0                  0.0   \n",
      "2015-01-01 02:00:00+00:00               78.0                  0.0   \n",
      "2015-01-01 03:00:00+00:00               78.0                  0.0   \n",
      "...                                      ...                  ...   \n",
      "2018-12-31 18:00:00+00:00               62.0                  2.0   \n",
      "2018-12-31 19:00:00+00:00               71.0                  1.0   \n",
      "2018-12-31 20:00:00+00:00               81.0                  3.0   \n",
      "2018-12-31 21:00:00+00:00               81.0                  2.0   \n",
      "2018-12-31 22:00:00+00:00               75.0                  2.0   \n",
      "\n",
      "                           wind_deg_Valencia  rain_1h_Valencia  \\\n",
      "time                                                             \n",
      "2014-12-31 23:00:00+00:00               62.0               0.0   \n",
      "2015-01-01 00:00:00+00:00               62.0               0.0   \n",
      "2015-01-01 01:00:00+00:00               23.0               0.0   \n",
      "2015-01-01 02:00:00+00:00               23.0               0.0   \n",
      "2015-01-01 03:00:00+00:00               23.0               0.0   \n",
      "...                                      ...               ...   \n",
      "2018-12-31 18:00:00+00:00              140.0               0.0   \n",
      "2018-12-31 19:00:00+00:00              242.0               0.0   \n",
      "2018-12-31 20:00:00+00:00              300.0               0.0   \n",
      "2018-12-31 21:00:00+00:00              310.0               0.0   \n",
      "2018-12-31 22:00:00+00:00              300.0               0.0   \n",
      "\n",
      "                           snow_3h_Valencia  clouds_all_Valencia  \n",
      "time                                                              \n",
      "2014-12-31 23:00:00+00:00               0.0                  0.0  \n",
      "2015-01-01 00:00:00+00:00               0.0                  0.0  \n",
      "2015-01-01 01:00:00+00:00               0.0                  0.0  \n",
      "2015-01-01 02:00:00+00:00               0.0                  0.0  \n",
      "2015-01-01 03:00:00+00:00               0.0                  0.0  \n",
      "...                                     ...                  ...  \n",
      "2018-12-31 18:00:00+00:00               0.0                  0.0  \n",
      "2018-12-31 19:00:00+00:00               0.0                  0.0  \n",
      "2018-12-31 20:00:00+00:00               0.0                  0.0  \n",
      "2018-12-31 21:00:00+00:00               0.0                  0.0  \n",
      "2018-12-31 22:00:00+00:00               0.0                  0.0  \n",
      "\n",
      "[35064 rows x 65 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAINCAYAAAAJGy/3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYp0lEQVR4nO3dd3xUVf7/8fekTXogCWkQQkKREookSreuIKiA6yo2BNt3sYJYVnQVRV38uYqshSiKhZVVdFFXd3GFRaSjgIA06ZAQEkICpJI2c39/BEZiAsnATO4keT0fj3nMzLllPnOIkLfn3nMshmEYAgAAAACclpfZBQAAAACApyM4AQAAAEAdCE4AAAAAUAeCEwAAAADUgeAEAAAAAHUgOAEAAABAHQhOAAAAAFAHghMAAAAA1MHH7AIamt1u18GDBxUSEiKLxWJ2OQAAAABMYhiGCgsLFRcXJy+vM48pNbvgdPDgQcXHx5tdBgAAAAAPkZGRoTZt2pxxn2YXnEJCQiRVdU5oaKjJ1QAAAAAwS0FBgeLj4x0Z4UyaXXA6eXleaGgowQkAAABAvW7hYXIIAAAAAKgDwQkAAAAA6kBwAgAAAIA6EJwAAAAAoA4EJwAAAACoA8EJAAAAAOpAcAIAAACAOhCcAAAAAKAOBCcAAAAAqAPBCQAAAADqQHACAAAAgDoQnAAAAACgDgQnAAAAAKgDwQkAAAAA6mBqcFq6dKmuueYaxcXFyWKx6Msvv6zzmCVLliglJUX+/v5KSkrSW2+95f5CAQAAADRrpgan4uJi9ezZU2+88Ua99t+7d6+GDRumQYMGaf369XriiSf04IMPat68eW6uFAAAAEBz5mPmhw8dOlRDhw6t9/5vvfWW2rZtq+nTp0uSunTporVr1+rll1/Wdddd56YqAQAAADR3pgYnZ61atUqDBw+u1jZkyBDNmjVLFRUV8vX1NakyAACAxsMwDNkNqcJml81uqNJmqNJuV6XdkM1uyG4YsttV9ex4yLHNMORoq3p/4rW96tkwDBmSDEOqenXyc088n1KHY1uNF78ee8puNc5Vy2HVvmeNtjP2TO3nPsOe9d0Rks6LCVViZJDZZZy1RhWcsrOzFR0dXa0tOjpalZWVys3NVWxsbI1jysrKVFZW5nhfUFDg9joBAABqU2mz63iFTcfLbVXPp7wurbDpeLnd0V56or280q5ym13llXaVVdpPeV+1rcJmqNxmV4XNrkqboYqTr08EoopTtlXaqwJShY1f+NHwnhzWRXdflGR2GWetUQUnSbJYLNXen/w/Cb9tP2nq1Kl69tln3V4XAABoGiptdhWXVwWa4vJKlZSdeC6vVHFZVXtJeaVKKk6+rnocL6+seq44+f7XYFRSXqnSiqrA48m8vSzytljk5SV5WapeWyySl9fJ1xZ5e0kWWeTtVbXNYqna1+vkvhaLvCxV+/z217OTv69ZHO9VbR/LiS3V207Z+Td+23KaXwfrcVzd58a5iwq1ml3COWlUwSkmJkbZ2dnV2nJycuTj46OIiIhaj5k0aZImTpzoeF9QUKD4+Hi31gkAABqOYRgqq7SrqKxSRaWVKiqrVOGJ5+KyShWeaC8u+7WtuLxqn+KyqjBUVHYiGJVXjeK4m8UiBfh6K9DPW/6+3grw9VbAqa9PbLP6esvq4yU/Hy/5eZ94PvX1iWdfby/5eFvkd+LZx8tLvt4WR7uvt5d8vKqevb0sVW1eXvI+8Vx1jOW0/yMaQCMLTv369dPXX39drW3BggVKTU097f1NVqtVVmvjTrcAADRVdrvhCDFVjwoVllaqoLTCEYBOtp18XVBaFYQKyyocQckdl575eFkU6OetIKuP4/lkoAn081GAX9XrAD9vBfr6/Pra0e5TLRwF+v0akKw+XoQUoJExNTgVFRVp165djvd79+7Vhg0bFB4errZt22rSpEnKzMzU7NmzJUnjxo3TG2+8oYkTJ+ruu+/WqlWrNGvWLH388cdmfQUAAJo1m91QYWmF8o9X6FhJhQpOBp/jVa8Ljv8adgqO/xqKTg1H9b8Rv25Bft4K9vdRsNVHwf6+CrH6KMjqrWCrr4KtVeEnyOqjEH8fBfmd8trqoyA/bwWefPbzkZ+Pqau2APAwpgantWvX6tJLL3W8P3lJ3ZgxY/TBBx8oKytL6enpju2JiYmaP3++HnroIb355puKi4vTa6+9xlTkAACcI5vdOBF+ynW0pPrzsZIKHTte9Zx//NeQlH8iHLki+Ph6WxTi76sQ/6ogE2I9+fqUthPvg62/vg49EXqCTwQhby9GcQC4h8WobZ7GJqygoEBhYWHKz89XaGio2eUAAOAWhmGosKxSeUXlyi0qU25hmXKLy5VbWKa84jLlFpZXPReV60hx+TkHoABfb4UF+CoswFehAT4KPRF4QgN8Fepf1VYVdHyrhaDQE/tw6RoAMziTDRrVPU4AADR3pRU2HS4sU05hqQ4XlulwUXnVc2GZcovKqr0uO4tJDoKtPmoR6KuWgX6O55aBvgoL9FOLE8GoReCvz6En2qw+3m74tgDgOQhOAAB4gAqbXTmFZTpUUKqcglIdKqh6faigKiSdfJ1/vMKp8wZbfRQR7KfIYKsigvwUGWJV5InniCCrIoL9FBHkpxYngpKvN/f1AEBtCE4AALiRYRgqKK1Udn6psvKPOwJQdkGpDuWXVj0XVF0+V99L5aw+XmoVYlVUiFWRwVa1Cql6nPq6VXDV+wA/RoIAwBUITgAAnIPC0godOHpcWfnHlZVfqqxjpcrKL1V2QdX77PxSlZTb6nUuX2+LokL8FR1qVXSov6JCrIoK9Vd06K9t0SH+Cg3w4X4gAGhgBCcAAM6grNKmzKPHlXH0uDKOlCjjaIkOHDmu9BOvj5XU79K5loG+ig71V0yYv2JC/RUVWvUcE2ZVVEhVe3ign7yYFQ4APBLBCQDQ7OWXVGj/kWLtzytR+pES7c8rVvqREqXnlSiroLTOS+haBvoqrkWAYsMCFBtWFYJ+fa5q8/flkjkAaMwITgCAZqGwtEJ7c4u153Cx9uQWa8/hIu3PqwpJBaWVZzw20M9b8S0DFR8eoDYtAxUfHqj4lgFVz+GBCrbyzykANHX8TQ8AaDLsdkMHjh7XjkOFVSEpt0i7Dxdrb26xDheWnfHYViFWJYQHqm1EoBLCg5QQUfW6bXigIoL8uKcIAJo5ghMAoNExDENZ+aXacajwxKNIOw4VauehIh2vOP1EDK1CrEqMDFL7VkFKjAxSu4ggJUQEKT48QIF+/JMIADg9/pUAAHi0I8Xl+iW7QDuyC7X9REDakV2owrLaL6/z8/FS+1bBat8qSEmtgpUUGaSkVkFqFxmkUH/fBq4eANBUEJwAAB6huKzSMYK0PbtI2w8VaHt2kXKLar/EztvLoqTIIHWKCVGnqBCdFxOsTtEhahseKB8WcQUAuBjBCQDQoE7eh7Qtu0Dbsgr0S1ahtmUXaH9eyWmPaRseqE7RIeocE6KO0cE6LyZEiZFBsvowUx0AoGEQnAAAblNSXqlfsgu1LavgxKNQ27MLVXSay+xahVjVOSZEnaJDdF50iDrFhKhjVLCCmLUOAGAy/iUCAJwzwzCUU1imrVkF2nqwQFuzCrTtYIH25hXXugaSn7eXOkQFq0tsqLrEhqhLbKg6x4QoItja8MUDAFAPBCcAgFPsdkN784q15WCBtmTmO8JSXnF5rfu3CrH+GpBiQtUlNlRJrYLky31IAIBGhOAEADitCptdu3KKtDkzvyooHczX1oMFKi6vOeW3l0VKahWsrrGh6hoX6ghLUSH+JlQOAIBrEZwAAJIkm93QrpwibTxwTBszjmlzZr62ZReqvNJeY19/Xy91iQ1Vt7hQdY0NU7e4UHWKDlGAH5M1AACaJoITADRDhmEo48hxR0j6+UC+Nh/MV0ktI0khVh91jQtVcuswJbcOVbe4MCVFBjHlNwCgWSE4AUAzUFBaoQ3px7Q+/ZjWZxzVxoxjOlpSUWO/ID9vJbcOU8/4FurRJkzdW4cpvmWgvLwsJlQNAIDnIDgBQBNjtxvafbhIP6Uf1U/7q4LSzpyiGrPb+Xl7qUtsiHq0qQpJveJbKKlVsLwJSQAA1EBwAoBGrqS8UhvSj2nNvqNau/+INmQcU2FpzXWS2oYHqnfbFjq/bUv1im+hzrEhLCALAEA9EZwAoJHJKSzVun1HtXb/Ua3dd0SbDxbIZq8+nBTg660ebcLUO6Glep8ISq1CWCMJAICzRXACAA9mGIb25hZrzb4jVSNK+45oX15Jjf1iw/x1QbtwpbarCkqdY0KYvAEAABciOAGAB6m02bUtq/BEUKp65BZVX1jWYpHOiw5xBKXUduFq3SLApIoBAGgeCE4AYKLySrvWpx/Vj3uP6Md9R7Q+/ZiKyqrfn+Tn46VebVootV1LXZAYrt5tWyoswNekigEAaJ4ITgDQgOx2Q9sPFWrFrlwt35WrH/Yc0fGK6msnhVh9lNKupS5oF64LE8PVo00YkzgAAGAyghMAuFnmseNasbMqKK3cnVvj0rvIYD/1SYzQBSdGlDrHhDIlOAAAHobgBAAuVlxWqdV78rRkx2Et35mrPbnF1bYH+HqrT1K4BnaI1MCOkTovOkQWC0EJAABPRnACgHNkGIZ+yS7U0h2HtWTHYa3dd1TlNrtju7eXRT3bhGlgh0gN6BCp89u2lJ8PM94BANCYEJwA4CwcKynXsp25WrrjsJbuPKxDBWXVtseHB+jiTq10UcdW6ts+QqH+TOYAAEBjRnACgHrKyj+uBVsO6b+bs/XjviPVFp0N8PVWv/YRuqhjpC4+L0rtIgK5/A4AgCaE4AQAZ7Arp0jfbsnWgi3Z2nggv9q2TtHBuuS8KF3UsZVS27WUvy8z3wEA0FQRnADgFIZhaFNmvv67OVvfbsnW7sO/TuxgsUipCS01pFuMBneNUduIQBMrBQAADYngBACSduUU6l8bDupfGw4q/UiJo93X26L+7SM1pFuMrugarVYhVhOrBAAAZiE4AWi2svKP6+uNVWFpy8ECR3ugn7cuPS9Kg7tF69LOUUzsAAAACE4Ampf8kgrN35ylf23I1A97j8g4Mb+Dj5dFl5zXSsN7tdYVXaIV4Mf9SgAA4FcEJwBNnt1uaNmuXH38Q7oW/XJIFbZfZ8O7sF24Rpwfp2HJsWoZ5GdilQAAwJMRnAA0WYcKSvXZ2gx9/GOGMo8dd7R3jgnRiF6tNbxXnFq3CDCxQgAA0FgQnAA0KTa7oaU7D58YXcpxrLUU6u+j61LaaNQF8eocE2pylQAAoLEhOAFoErLzS/Xp2gzNXVN9dOmCdi11c5+2GpocyzpLAADgrBGcADRahmFoxa48/X31Pv1v26+jS2EBvrqudxvddGG8OkaHmFwlAABoCghOABqd/OMVmrfugD5avV97cn9doPbCduG6uU9bXZkcw+gSAABwKYITgEZjy8F8/X3Vfv1rw0Edr7BJkoKtPvp979a6tW+COjG6BAAA3ITgBMCjlVXaNH9Tlv6+ar9+Sj/maD8vOkSj+yVo5PmtFWzlrzIAAOBe/LYBwCMdKS7XR6v3a/aq/cotKpNUtUjt0O6xGt03QRe0aymLxWJylQAAoLkgOAHwKHsOF2nW8r2a99MBlVbYJUkxof66pU9bjbowXlEh/iZXCAAAmiOCEwDTGYahH/Ye0bvL9mjRLzkyqibHU3LrUN09KEnDusfK19vL3CIBAECzRnACYJoKm13zN2Xp3WV7tSkz39H+uy5RunNgkvomhXM5HgAA8AgEJwANzmY39MX6TL26cIdjsVqrj5euS2mjOwcmqn2rYJMrBAAAqI7gBKDBGIah73cc1v/75hf9kl0oSYoM9tNt/drplj5tFRFsNblCAACA2hGcADSITQfyNfWbbVq5O0+SFOrvo/su7aAx/duxWC0AAPB4BCcAbpVxpER//Xa7vtp4UJLk5+2lMf0TdN+lHdQi0M/k6gAAAOqH4ATALY4Ul+v173bqo9X7VWEzZLFII3u11sQrOik+PNDs8gAAAJxCcALgUqUVNr23Yq/SFu9WYVmlJGlQx0j96crOSm4dZnJ1AAAAZ4fgBMAl7CdmyntlwXYdzC+VJHWNDdWkYZ01qGMrk6sDAAA4NwQnAOdsxa5c/WX+Nm05WCBJigvz1yNDztPIXq3l5cU6TAAAoPEjOAE4a9uzCzX1m236fvthSVKI1Uf3XtpBtw9gpjwAANC0EJwAOC2noFTTFu7Qp2szZDckHy+Lbu2boAcv76jwIGbKAwAATQ/BCUC9lVbY9NaS3Xp7yR4dr7BJkoYmx+ixKzsrMTLI5OoAAADch+AEoF5W7c7TE19s0t7cYklS77Yt9ORVXZSSEG5yZQAAAO5HcAJwRkeLy/WX+dv02boDkqSoEKueurqrru4RK4uFiR8AAEDzQHACUCvDMPSvDQf13L+3Kq+4XJJ0a9+2euzKzgr19zW5OgAAgIZFcAJQQ3peiZ78cpOW7cyVJHWKDtbU33fnsjwAANBsEZwAOFTY7Jq1fK+m/2+HSivs8vPx0oOXddD/XdRefj5eZpcHAABgGoITAEnSpgP5emzez9qWVbWIbb+kCP3l992ZLQ8AAEAEJ6DZK6u06fVFu5S2ZLdsdkMtAn315LAu+kNKGyZ/AAAAOIHgBDRjmw7k65HPNmr7oUJJ0lU9YjVleDdFBFtNrgwAAMCzEJyAZqi80q7Xv9upGd9XjTJFBPnpuZHJGtY91uzSAAAAPBLBCWhmNmdWjTL9ks0oEwAAQH0RnIBm4rejTOFBfnqeUSYAAIB6ITgBzcCWg/l6+NNTRpm6x2rKCEaZAAAA6ovgBDRhhmHo4x8z9MxXW1Rusys8yE/PjUjWVT0YZQIAAHAGwQlookorbPrzl5v1z3UHJEm/6xKtF6/rrkhGmQAAAJxGcAKaoP15xRr30U/allUgL4v06JDO+uNFSfLyYl0mAACAs0FwApqYRdsOacLcDSosrVREkJ9ev+l89e8QaXZZAAAAjRrBCWgibHZDry7coTcW75Ik9W7bQjNuSVFMmL/JlQEAADR+BCegCcgrKtP4TzZo+a5cSdLY/u30xLAu8vPxMrkyAACApsH036pmzJihxMRE+fv7KyUlRcuWLTvj/nPmzFHPnj0VGBio2NhY3X777crLy2ugagHPsyHjmK55fbmW78pVgK+3/nZjLz0zvBuhCQAAwIVM/c1q7ty5mjBhgp588kmtX79egwYN0tChQ5Wenl7r/suXL9dtt92mO++8U1u2bNFnn32mNWvW6K677mrgygHPMHdNum54a5UO5pcqKTJIX943QCN6tTa7LAAAgCbHYhiGYdaH9+nTR71791ZaWpqjrUuXLho5cqSmTp1aY/+XX35ZaWlp2r17t6Pt9ddf10svvaSMjIx6fWZBQYHCwsKUn5+v0NDQc/8SgAkqbXY9/59t+mDlPknSld1i9NfreyjE39fcwgAAABoRZ7KBaSNO5eXlWrdunQYPHlytffDgwVq5cmWtx/Tv318HDhzQ/PnzZRiGDh06pH/+85+66qqrGqJkwCMcKynX2PfXOELTxCs6Ke3W3oQmAAAANzJtcojc3FzZbDZFR0dXa4+OjlZ2dnatx/Tv319z5szRqFGjVFpaqsrKSg0fPlyvv/76aT+nrKxMZWVljvcFBQWu+QKACXYeKtRds9dqf16JAv28Ne2GXroyOcbssgAAAJo80+8et1iqL8hpGEaNtpO2bt2qBx98UE8//bTWrVun//73v9q7d6/GjRt32vNPnTpVYWFhjkd8fLxL6wcayv+2HtK1M1Zqf16J2rQM0Of39ic0AQAANBDT7nEqLy9XYGCgPvvsM1177bWO9vHjx2vDhg1asmRJjWNGjx6t0tJSffbZZ4625cuXa9CgQTp48KBiY2NrHFPbiFN8fDz3OKHRMAxDaUt266/fbpdhSH0Sw5V2a4rCg/zMLg0AAKBRaxT3OPn5+SklJUULFy6s1r5w4UL179+/1mNKSkrk5VW9ZG9vb0lVv1zWxmq1KjQ0tNoDaCyOl9s0/pMNeum/VaHp1r5t9dFdfQhNAAAADczUBXAnTpyo0aNHKzU1Vf369dPMmTOVnp7uuPRu0qRJyszM1OzZsyVJ11xzje6++26lpaVpyJAhysrK0oQJE3ThhRcqLi7OzK8CuFxW/nH93+x12pSZLx8vi54Z3k239k0wuywAAIBmydTgNGrUKOXl5WnKlCnKyspScnKy5s+fr4SEql8Os7Kyqq3pNHbsWBUWFuqNN97Qww8/rBYtWuiyyy7T//t//8+srwC4xdaDBbr9gx91qKBMLQN9lXZrivomRZhdFgAAQLNl6jpOZmAdJ3i6ZTsP656PflJRWaU6RgXrvbEXKD480OyyAAAAmhxnsoGpI04AqvtsbYYmfb5JlXZDfZPC9fboVIUFsD4TAACA2QhOgAcwDEN/W7RT0/+3U5I0olecXvpDD1l9vE2uDAAAABLBCTBdhc2uJ7/YpE/XHpAk3XtJez0y+Dx5edW+nhkAAAAaHsEJMFFRWaXunfOTlu44LC+LNGVEMjPnAQAAeCCCE2CSQwWluv39NdqaVaAAX2+9cfP5urxLtNllAQAAoBYEJ8AEOw4Vaux7P+pgfqkig/00a8wF6hnfwuyyAAAAcBoEJ6CBbc7M183vrFZBaaWSIoP0we0Xqm0E040DAAB4MoIT0IB25RTptvd+VEFppXq3baFZYy5QyyA/s8sCAABAHQhOQAPJOFKiW9/9QUeKy9W9dZg+vONChfizRhMAAEBj4GV2AUBzkFNYqtGzflB2Qak6RAUTmgAAABoZghPgZsdKyjX63R+1L69E8eEB+ujOPgrn8jwAAIBGheAEuFFRWaXGvr9G2w8VKirEqjl39lVMmL/ZZQEAAMBJBCfATUorbPq/2Wu1IeOYWgT66qO7+jB7HgAAQCNFcALcoMJm1/3/WK+Vu/MU5OetD2+/UJ2iQ8wuCwAAAGeJ4AS4mN1u6NHPNup/2w7J6uOld1ncFgAAoNEjOAEuZBiGnv5qs77ccFA+Xhal3dpb/dpHmF0WAAAAzhHBCXChVxbs0Eer02WxSNNG9dJlnaPNLgkAAAAuQHACXGT2qn16Y/EuSdLzI5M1vGecyRUBAADAVQhOgAvM35SlyV9tkSRNvKKTbumTYHJFAAAAcCWCE3COVu/J04RPNsgwpFv6tNUDl3UwuyQAAAC4GMEJOAe/ZBfo7tlrVW6za3DXaE0ZkSyLxWJ2WQAAAHAxghNwljKPHdfY99aosLRSqQkt9dpN58vbi9AEAADQFBGcgLNwrKRcY977UdkFpeoYFax3x6TK39fb7LIAAADgJgQnwEmlFTbd+eFa7copUkyovz6840K1CPQzuywAAAC4EcEJcEKlza77/7Fe6/YfVai/j2bfeaHiWgSYXRYAAADcjOAE1JNhGHrqX1v0v22H5OfjpXfHXKBO0SFmlwUAAIAGQHAC6um1Rbv08Y/pslik127spQsTw80uCQAAAA2E4ATUwzebsvTq/3ZIkqaMSNaVybEmVwQAAICGRHAC6rArp1CPfLZRknTXwESN7ptgckUAAABoaAQn4AwKSyv0f39fp+Jym/omhevxoZ3NLgkAAAAmIDgBp2G3G3r4043ac7hYsWH+euPm3vLx5j8ZAACA5ojfAoHTSFuyWwu2HpKft5fSbk1RZLDV7JIAAABgEoITUIulOw7rlQXbJUnPjuimXvEtzC0IAAAApiI4Ab+RcaRED36yXnZDuvGCeN10YVuzSwIAAIDJCE7AKUorbBr30TodK6lQzzZhemZ4N7NLAgAAgAcgOAEnGIahJ7/YrC0HCxQR5Ke0W1Pk7+ttdlkAAADwAAQn4ISPfkjXvJ8OyMsivX7z+YprEWB2SQAAAPAQBCdA0rr9RzTl6y2SpMeHdlb/9pEmVwQAAABPQnBCs5dTWKp7PvpJFTZDV3WP1d2DkswuCQAAAB6G4IRmzWY3NOGTDcopLFPHqGC99IceslgsZpcFAAAAD0NwQrP2xne7tHJ3ngL9vJV2a4qCrD5mlwQAAAAPRHBCs7Vqd57+tmiHJOmFa5PVISrY5IoAAADgqQhOaJZyi8o0/sQit9entNG157cxuyQAAAB4MIITmh273dBDc3+9r+nZESxyCwAAgDMjOKHZSVuyW8t25srf10tv3tJbgX7c1wQAAIAzIzihWVmz74imLay6r2nK8GR1ig4xuSIAAAA0BgQnNBtHisv1wD/Wy2Y3dO35rXV9Kvc1AQAAoH4ITmgW7HZDj3y2UdkFpUqKDNLzI5NZrwkAAAD1RnBCs/Du8j367pcc+fl46Y2be7NeEwAAAJxyTsGptLTUVXUAbvNT+lG99N/tkqTJ13RV17hQkysCAABAY+N0cLLb7XruuefUunVrBQcHa8+ePZKkp556SrNmzXJ5gcC5yC+p0AP/WK9Ku6Gre8Tq5gvbml0SAAAAGiGng9Pzzz+vDz74QC+99JL8/Pwc7d27d9e7777r0uKAc2EYhh6bt1GZx44rISJQU3/fnfuaAAAAcFacDk6zZ8/WzJkzdcstt8jb29vR3qNHD/3yyy8uLQ44F3PXZOjbLYfk623RGzf1Voi/r9klAQAAoJFyOjhlZmaqQ4cONdrtdrsqKipcUhRwrvbmFuvZr7dKkh4dcp66twkzuSIAAAA0Zk4Hp27dumnZsmU12j/77DOdf/75LikKOBcVNrsmzN2g4xU29UuK0F0Dk8wuCQAAAI2c03MyT548WaNHj1ZmZqbsdrs+//xzbd++XbNnz9a///1vd9QIOOWN73ZpY8Yxhfj76JUbesrLi/uaAAAAcG6cHnG65pprNHfuXM2fP18Wi0VPP/20tm3bpq+//lpXXHGFO2oE6m3d/qN6Y/EuSdIL13ZXXIsAkysCAABAU3BWq4AOGTJEQ4YMcXUtwDkpKqvUxE83yGY3NLJXnIb3jDO7JAAAADQRTo84rVmzRj/88EON9h9++EFr1651SVHA2Xju663an1ei1i0C9OyIZLPLAQAAQBPidHC67777lJGRUaM9MzNT9913n0uKApz1383Zmrs2QxaL9MoNPRUWwNTjAAAAcB2ng9PWrVvVu3fvGu3nn3++tm7d6pKiAGfkFJRq0uc/S5L+eFF79U2KMLkiAAAANDVOByer1apDhw7VaM/KypKPz1ndMgWcNcMw9Mg/f9bRkgp1jQ3VxCs6mV0SAAAAmiCng9MVV1yhSZMmKT8/39F27NgxPfHEE8yqhwY3e9V+Ld1xWFYfL712Uy/5+Tj9Iw0AAADUyekholdeeUUXXXSREhISHAvebtiwQdHR0fr73//u8gKB09l5qFB/mb9NkvTkVV3UISrE5IoAAADQVDkdnFq3bq2ff/5Zc+bM0caNGxUQEKDbb79dN910k3x9uSEfDaO80q7xn2xQWaVdF3dqpdF9E8wuCQAAAE3YWd2UFBQUpP/7v/9zdS1Avb25eJe2ZhUoPMhPf72+hywWi9klAQAAoAk7q+C0Y8cOff/998rJyZHdbq+27emnn3ZJYcDp7DhUqBnf75IkTRnRTVEh/iZXBAAAgKbO6eD0zjvv6J577lFkZKRiYmKq/Z9+i8VCcIJb2eyGHvvnz6qwGfpdl2hd1T3W7JIAAADQDDgdnJ5//nm98MIL+tOf/uSOeoAz+nDlPm3IOKYQq4+eH5nMJXoAAABoEE7P3Xz06FFdf/317qgFOKOMIyX667fbJUmPD+usmDAu0QMAAEDDcDo4XX/99VqwYIE7agFOyzAMPfHFJh2vsOnCxHDddEFbs0sCAABAM+L0pXodOnTQU089pdWrV6t79+41piB/8MEHXVYccNLnP2Vq2c5c+fl46cXfd5eXF5foAQAAoOFYDMMwnDkgMTHx9CezWLRnz55zLsqdCgoKFBYWpvz8fIWGhppdDuoht6hMv5u2RMdKKvTYlefp3ks6mF0SAAAAmgBnsoHTI0579+4968KAs/HMV1t0rKRCXWNDdfegJLPLAQAAQDPk9D1OQEP639ZD+vfPWfL2suilP/SQrzc/sgAAAGh4Z7UA7oEDB/TVV18pPT1d5eXl1bZNmzbNJYUBBaUV+vOXmyVJdw1MVHLrMJMrAgAAQHPldHBatGiRhg8frsTERG3fvl3Jycnat2+fDMNQ79693VEjmqn/980vyi4oVUJEoCb8rpPZ5QAAAKAZc/q6p0mTJunhhx/W5s2b5e/vr3nz5ikjI0MXX3zxWa3vNGPGDCUmJsrf318pKSlatmzZGfcvKyvTk08+qYSEBFmtVrVv317vvfee058Lz/bDnjzN+SFdkjT1990V4OdtckUAAABozpwecdq2bZs+/vjjqoN9fHT8+HEFBwdrypQpGjFihO655556n2vu3LmaMGGCZsyYoQEDBujtt9/W0KFDtXXrVrVtW/s6PTfccIMOHTqkWbNmqUOHDsrJyVFlZaWzXwMerLTCpkmfb5Ik3XhBvPq3jzS5IgAAADR3TgenoKAglZWVSZLi4uK0e/dudevWTZKUm5vr1LmmTZumO++8U3fddZckafr06fr222+VlpamqVOn1tj/v//9r5YsWaI9e/YoPDxcktSuXTtnvwI83Ovf7dSe3GJFhVg1aVgXs8sBAAAAnL9Ur2/fvlqxYoUk6aqrrtLDDz+sF154QXfccYf69u1b7/OUl5dr3bp1Gjx4cLX2wYMHa+XKlbUe89VXXyk1NVUvvfSSWrdurU6dOumRRx7R8ePHnf0a8FC7cgo1c2nVWmBTRnRTWIBvHUcAAAAA7uf0iNO0adNUVFQkSXrmmWdUVFSkuXPnqkOHDnr11VfrfZ7c3FzZbDZFR0dXa4+OjlZ2dnatx+zZs0fLly+Xv7+/vvjiC+Xm5uree+/VkSNHTnufU1lZmWOETKpa5AqeyTAM/fnLzaqwGbq8c5SGdIsxuyQAAABA0lkEp6SkXxcgDQwM1IwZM86pAIvFUu29YRg12k6y2+2yWCyaM2eOwsKqpqaeNm2a/vCHP+jNN99UQEBAjWOmTp2qZ5999pxqRMP4Yn2mVu85In9fLz0zvNtpfw4AAACAhmbaaqKRkZHy9vauMbqUk5NTYxTqpNjYWLVu3doRmiSpS5cuMgxDBw4cqPWYSZMmKT8/3/HIyMhw3ZeAy+SXVOgv87dJkh64rKPiwwNNrggAAAD4Vb2CU3h4uGPih5YtWyo8PPy0j/ry8/NTSkqKFi5cWK194cKF6t+/f63HDBgwQAcPHnRcKihJO3bskJeXl9q0aVPrMVarVaGhodUe8Dx/XfCLcovK1SEqWHcPSqr7AAAAAKAB1etSvVdffVUhISGSqma+c5WJEydq9OjRSk1NVb9+/TRz5kylp6dr3LhxkqpGizIzMzV79mxJ0s0336znnntOt99+u5599lnl5ubq0Ucf1R133FHrZXpoHDZkHHOs2fTciGT5+Zg2EAoAAADUql7BacyYMZLkWC9pyJAhiok59xv3R40apby8PE2ZMkVZWVlKTk7W/PnzlZCQIEnKyspSenq6Y//g4GAtXLhQDzzwgFJTUxUREaEbbrhBzz///DnXAnPY7Ib+/OUmGYb0+/Nbq1/7CLNLAgAAAGqwGIZhOHNAYGCgtm3b5gg3jU1BQYHCwsKUn5/PZXse4IMVe/XM11sV6u+jRQ9folYhVrNLAgAAQDPhTDZw+pqoPn36aP369WddHHBSTkGpXlmwQ5L06JWdCU0AAADwWE5PR37vvffq4Ycf1oEDB5SSkqKgoKBq23v06OGy4tC0PfefbSosq1TPNmG6+cK2ZpcDAAAAnJbTl+p5edUcpLJYLI71l2w2m8uKcwcu1fMMy3Ye1uhZP8rLIn11/0Altw6r+yAAAADAhZzJBk6POO3du/esCwMkqazSpqf/tUWSdFu/doQmAAAAeDyng1NjnRQCnuPtJXu0N7dYrUKsmji4k9nlAAAAAHVyOjidtHXrVqWnp6u8vLxa+/Dhw8+5KDRd+/OK9cbiXZKkp67uqlB/X5MrAgAAAOrmdHDas2ePrr32Wm3atMlxb5NUdZ+TJI+/xwnmMQxDT/9ri8or7RrYIVLX9Ig1uyQAAACgXpyejnz8+PFKTEzUoUOHFBgYqC1btmjp0qVKTU3V999/74YS0VQs2pajJTsOy8/bS1NGdHOEbQAAAMDTOT3itGrVKn333Xdq1aqVvLy85OXlpYEDB2rq1Kl68MEHWeMJtSqvtOuF+dskSXcMTFRSq2CTKwIAAADqz+kRJ5vNpuDgql96IyMjdfDgQUlVk0Zs377dtdWhyZi9ap/25hYrMtiq+y5tb3Y5AAAAgFOcHnFKTk7Wzz//rKSkJPXp00cvvfSS/Pz8NHPmTCUlJbmjRjRyR4rL9bdFOyVJjw7ppBAmhAAAAEAj43Rw+vOf/6zi4mJJ0vPPP6+rr75agwYNUkREhObOnevyAtH4vbpwhwpLK9U1NlR/SIk3uxwAAADAaU4HpyFDhjheJyUlaevWrTpy5IhatmzJzf6oYXt2oeb8sF9S1fTj3l78jAAAAKDxcfoepw8//NAx4nRSeHg4oQk1GIah5/+zVXZDurJbjPq1jzC7JAAAAOCsOB2cHnnkEUVFRenGG2/Uv//9b1VWVrqjLjQBi7fnaNnOXPl5e2nSsM5mlwMAAACcNaeDU1ZWlubOnStvb2/deOONio2N1b333quVK1e6oz40UhU2u57/d9X047cPbKeEiCCTKwIAAADOntPBycfHR1dffbXmzJmjnJwcTZ8+Xfv379ell16q9u2ZZhpV/r5qv/bkFisy2E/3X9rB7HIAAACAc+L05BCnCgwM1JAhQ3T06FHt379f27Ztc1VdaMSOFpdr+v92SJIeHnwe048DAACg0XN6xEmSSkpKNGfOHA0bNkxxcXF69dVXNXLkSG3evNnV9aERmv6/HSoorVTnmBDdkMr04wAAAGj8nB5xuummm/T1118rMDBQ119/vb7//nv179/fHbWhEdp5qFAf/ZAuSXqa6ccBAADQRDgdnCwWi+bOnashQ4bIx+ecrvRDE/T8f7bJZjd0Rddo9e8QaXY5AAAAgEs4nXz+8Y9/uKMONAGLt+doyY7D8vW26IlhXcwuBwAAAHCZs7rHCfitCptdL/ynanKQsf3bKTGS6ccBAADQdBCc4BKf/JiuXTlFCg/y0/2XdTS7HAAAAMClCE44Z6UVNr3+3S5J0oTfdVRYANOPAwAAoGkhOOGczfkhXTmFZWrdIkA3XtDW7HIAAAAAl6vX5BAFBQX1PmFoaOhZF4PG53i5TWnf75Yk3X9ZB/n5kMUBAADQ9NQrOLVo0UIWS/3W47HZbOdUEBqXj1bvV25Rmdq0DNAfUtqYXQ4AAADgFvUKTosXL3a83rdvnx5//HGNHTtW/fr1kyStWrVKH374oaZOneqeKuGRSsor9daSqtGmBy/rKF9vRpsAAADQNNUrOF188cWO11OmTNG0adN00003OdqGDx+u7t27a+bMmRozZozrq4RHmr1qv/KKy5UQEahre7c2uxwAAADAbZweIli1apVSU1NrtKempurHH390SVHwfEVllXr7xGjTA4w2AQAAoIlz+rfd+Ph4vfXWWzXa3377bcXHx7ukKHi+D1fu09GSCiVGBmlkrzizywEAAADcql6X6p3q1Vdf1XXXXadvv/1Wffv2lSStXr1au3fv1rx581xeIDxPYWmF3lm2R5L04OUd5MNoEwAAAJo4p3/jHTZsmHbs2KHhw4fryJEjysvL04gRI7Rjxw4NGzbMHTXCw3ywYp+OlVQoqVWQhvfk3iYAAAA0fU6POElVl+v95S9/cXUtaATyj/862jT+8o7y9qrfNPUAAABAY3ZW11gtW7ZMt956q/r376/MzExJ0t///nctX77cpcXB87y/Yq8KSivVMSpYV/fg3iYAAAA0D04Hp3nz5mnIkCEKCAjQTz/9pLKyMklSYWEho1BNXH5JhWYt2ytJmvC7Tow2AQAAoNlwOjg9//zzeuutt/TOO+/I19fX0d6/f3/99NNPLi0OnmXW8j0qLKtU55gQDU2OMbscAAAAoME4HZy2b9+uiy66qEZ7aGiojh075oqa4IGOlZTrvRX7JEkTftdRXow2AQAAoBlxOjjFxsZq165dNdqXL1+upKQklxQFz/POsj0qKqtUl9hQDe7KaBMAAACaF6eD0x//+EeNHz9eP/zwgywWiw4ePKg5c+bokUce0b333uuOGmGyI8Xl+uDEaNNDjDYBAACgGXJ6OvLHHntM+fn5uvTSS1VaWqqLLrpIVqtVjzzyiO6//3531AiTzVy6R8XlNiW3DtUVXaPNLgcAAABocBbDMIyzObCkpERbt26V3W5X165dFRwc7Ora3KKgoEBhYWHKz89XaGio2eV4vPzjFeo3dZFKym2aNSZVl3chOAEAAKBpcCYbnNUCuJIUGBio1NTUsz0cjcTcNekqKbepc0yILuscZXY5AAAAgCmcDk7FxcV68cUXtWjRIuXk5Mhut1fbvmfPHpcVB3NV2uz6cOV+SdIdAxJlsXBvEwAAAJonp4PTXXfdpSVLlmj06NGKjY3ll+kmbMHWQ8o8dlzhQX4a3ivO7HIAAAAA0zgdnL755hv95z//0YABA9xRDzzIe8v3SpJu7dNW/r7eJlcDAAAAmMfp6chbtmyp8PBwd9QCD7Ix45jW7j8qX2+Lbu2bYHY5AAAAgKmcDk7PPfecnn76aZWUlLijHniI91dUjTZd0yNOUaH+JlcDAAAAmMvpS/VeeeUV7d69W9HR0WrXrp18fX2rbf/pp59cVhzMcaigVP/+OUuSdPuARJOrAQAAAMzndHAaOXKkG8qAJ5m9ap8q7YYubBeu7m3CzC4HAAAAMJ3TwWny5MnuqAMe4ni5Tf/4IV2SdMfAduYWAwAAAHgIp+9xQtP25YZMHS2pUJuWAbqia4zZ5QAAAAAeoV4jTuHh4dqxY4ciIyPVsmXLM67ddOTIEZcVh4ZlGIZjCvKx/dvJ24s1ugAAAACpnsHp1VdfVUhIiCRp+vTp7qwHJlq+K1c7c4oU5OetGy6IN7scAAAAwGPUKziNGTOm1tdoWk6ONl2fGq9Qf9869gYAAACaD6cnhzjV8ePHVVFRUa0tNDT0nAqCOXYfLtLi7YdlsVRdpgcAAADgV05PDlFcXKz7779fUVFRCg4OVsuWLas90Dh9sGKfJOnyztFqFxlkbjEAAACAh3E6OD322GP67rvvNGPGDFmtVr377rt69tlnFRcXp9mzZ7ujRrhZfkmF/rnugCSmIAcAAABq4/Slel9//bVmz56tSy65RHfccYcGDRqkDh06KCEhQXPmzNEtt9zijjrhRp+sSdfxCps6x4SoX1KE2eUAAAAAHsfpEacjR44oMTFRUtX9TCenHx84cKCWLl3q2urgdpU2uz5cuU+SdMfAxDNONQ8AAAA0V04Hp6SkJO3bt0+S1LVrV3366aeSqkaiWrRo4cra0AD+uyVbB/NLFRHkp+E948wuBwAAAPBITgen22+/XRs3bpQkTZo0yXGv00MPPaRHH33U5QXCvU5OQX5L3wT5+3qbXA0AAADgmZy+x+mhhx5yvL700kv1yy+/aO3atWrfvr169uzp0uLgXhsyjumn9GPy9bbo1r5tzS4HAAAA8FjntI6TJLVt21Zt2/JLd2M0d026JOmq7rGKCvE3uRoAAADAc9UrOL322mv1PuGDDz541sWg4Rwvt+nfG7MkSTdcEG9yNQAAAIBnq1dwevXVV+t1MovFQnBqJBZszVZhWaVatwhQ30SmIAcAAADOpF7Bae/eve6uAw3s5IK316W0kZcXU5ADAAAAZ+L0rHqnMgxDhmG4qhY0kIPHjmv5rlxJ0nW9W5tcDQAAAOD5zio4zZo1S8nJyfL395e/v7+Sk5P17rvvuro2uMkX6zNlGNKFieFKiAgyuxwAAADA4zk9q95TTz2lV199VQ888ID69esnSVq1apUeeugh7du3T88//7zLi4TrGIbhuEzvDyltTK4GAAAAaBycDk5paWl65513dNNNNznahg8frh49euiBBx4gOHm4n9KPam9usQL9vHVV91izywEAAAAaBacv1bPZbEpNTa3RnpKSosrKSpcUBfc5Odo0NDlWQdZzXsYLAAAAaBacDk633nqr0tLSarTPnDlTt9xyi0uKgnucunYTl+kBAAAA9XdWQw6zZs3SggUL1LdvX0nS6tWrlZGRodtuu00TJ0507Ddt2jTXVAmXOLl2U5uWAeqTGG52OQAAAECj4XRw2rx5s3r37i1J2r17tySpVatWatWqlTZv3uzYz2JhbSBP41i7qTdrNwEAAADOcDo4LV682B11wM2qr93EZXoAAACAM5y+x+nQoUOn3fbzzz87XcCMGTOUmJgof39/paSkaNmyZfU6bsWKFfLx8VGvXr2c/szm6OTaTX0Sw9U2ItDscgAAAIBGxeng1L17d3311Vc12l9++WX16dPHqXPNnTtXEyZM0JNPPqn169dr0KBBGjp0qNLT0894XH5+vm677TZdfvnlTn1ec8XaTQAAAMC5cTo4/elPf9KoUaM0btw4HT9+XJmZmbrsssv017/+VXPnznXqXNOmTdOdd96pu+66S126dNH06dMVHx9f66x9p/rjH/+om2++2bEAL87s1LWbhrF2EwAAAOA0p4PTww8/rNWrV2vFihXq0aOHevTooYCAAP38888aPnx4vc9TXl6udevWafDgwdXaBw8erJUrV572uPfff1+7d+/W5MmTnS292WLtJgAAAODcnNVv0UlJSerWrZvmzZsnSbrhhhsUHR3t1Dlyc3Nls9lqHBcdHa3s7Oxaj9m5c6cef/xxLVu2TD4+9Su9rKxMZWVljvcFBQVO1dnYsXYTAAAAcO6cHnE6OdK0a9cu/fzzz0pLS9MDDzygG264QUePHnW6gN9OW24YRq1TmdtsNt1888169tln1alTp3qff+rUqQoLC3M84uPjna6xMWPtJgAAAODcOR2cLrvsMo0aNUqrVq1Sly5ddNddd2n9+vU6cOCAunfvXu/zREZGytvbu8boUk5OTq2jV4WFhVq7dq3uv/9++fj4yMfHR1OmTNHGjRvl4+Oj7777rtbPmTRpkvLz8x2PjIwM575wI8faTQAAAMC5c/pSvQULFujiiy+u1ta+fXstX75cL7zwQr3P4+fnp5SUFC1cuFDXXnuto33hwoUaMWJEjf1DQ0O1adOmam0zZszQd999p3/+859KTEys9XOsVqusVmu962pKWLsJAAAAcA2ng9NvQ9NJXl5eeuqpp5w618SJEzV69GilpqaqX79+mjlzptLT0zVu3DhJVaNFmZmZmj17try8vJScnFzt+KioKPn7+9doRxXWbgIAAABco96X6g0bNkz5+fmO9y+88IKOHTvmeJ+Xl6euXbs69eGjRo3S9OnTNWXKFPXq1UtLly7V/PnzlZCQIEnKysqqc00n1I61mwAAAADXsRiGYdRnR29vb2VlZSkqKkpS1aVzGzZsUFJSkiTp0KFDiouLk81mc1+1LlBQUKCwsDDl5+crNDTU7HLcZt3+I7oubZUC/by15snfMQ05AAAA8BvOZIN6jzj9Nl/VM2/BJKzdBAAAALiO07PqwfMZhqGFWw9Jkq49v7XJ1QAAAACNX72Dk8ViqbG+Um3rLcF8O3OKlFtULn9fL12Q2NLscgAAAIBGr97XcBmGobFjxzqm9i4tLdW4ceMUFBQkSSorK3NPhXDaihNTkF/QLlxWH2+TqwEAAAAav3oHpzFjxlR7f+utt9bY57bbbjv3inDOVu7OkyT1ax9hciUAAABA01Dv4PT++++7sw64iM1uaPWequA0oH2kydUAAAAATQOTQzQxWw7mq7C0UiH+PuoW13SnWwcAAAAaEsGpiVmxq2q0qU9ihHy8+eMFAAAAXIHfrJuYlburJoboz/1NAAAAgMsQnJqQ8kq71uw7Ikka0IH7mwAAAABXITg1IRsyjqm0wq6IID91ig42uxwAAACgySA4NSEn12/q1z6CxYkBAAAAFyI4NSGrTqzf1J9pyAEAAACXIjg1ESXllVqfcVSSNKADE0MAAAAArkRwaiLW7juqCpuh1i0C1DY80OxyAAAAgCaF4NRErNjN/U0AAACAuxCcmohf72/iMj0AAADA1QhOTUB+SYU2Z+ZLYmIIAAAAwB0ITk3AD3vzZDekpFZBignzN7scAAAAoMkhODUBK7lMDwAAAHArglMTsPLExBBcpgcAAAC4B8GpkTtcWKYdh4okSX2TGHECAAAA3IHg1Mit2lN1mV7X2FCFB/mZXA0AAADQNBGcGrmVu05epsdoEwAAAOAuBKdGzjExRAeCEwAAAOAuBKdGLONIidKPlMjby6IL2oWbXQ4AAADQZBGcGrGT9zf1bBOmEH9fk6sBAAAAmi6CUyP26/1NTEMOAAAAuBPBqZEyDIOFbwEAAIAGQnBqpHYfLlZOYZn8fLzUO6Gl2eUAAAAATRrBqZFatbvqMr3UhJby9/U2uRoAAACgaSM4NVIrdnGZHgAAANBQCE6NkN1uOGbU68fEEAAAAIDbEZwaoa1ZBco/XqEgP2/1aBNmdjkAAABAk0dwaoRWnZhNr09ShHy9+SMEAAAA3I3fuhuhFbtPrt/E/U0AAABAQyA4NTIVNrt+3HtEktSP4AQAAAA0CIJTI7MpM18l5Ta1CPRVl5hQs8sBAAAAmgWCUyOzPv2YJCmlbUt5eVnMLQYAAABoJghOjczGjGOSpF7xLUytAwAAAGhOCE6NzIYTwaknwQkAAABoMASnRiSvqEzpR0okEZwAAACAhkRwakR+PpAvSUpqFaSwAF+TqwEAAACaD4JTI7L+5P1NbVqYWgcAAADQ3BCcGhHHxBBtW5haBwAAANDcEJwaCcMwtPHAMUlST0acAAAAgAZFcGok9uWV6FhJhfx8vNQlloVvAQAAgIZEcGokTl6m1y0uVH4+/LEBAAAADYnfwBsJx/pNXKYHAAAANDiCUyNxMjidz8QQAAAAQIMjODUCZZU2bT1YIIkRJwAAAMAMBKdGYFtWocptdrUM9FVCRKDZ5QAAAADNDsGpETg5MUTP+BayWCzmFgMAAAA0QwSnRoCJIQAAAABzEZwagZMjTr2YGAIAAAAwBcHJw+WXVGhPbrEkRpwAAAAAsxCcPNyGA8ckSQkRgQoP8jO3GAAAAKCZIjh5OMdlevEtTK0DAAAAaM4ITh6OiSEAAAAA8xGcPJhhGEwMAQAAAHgAgpMHO3D0uPKKy+XrbVHX2FCzywEAAACaLYKTB1t/YrSpS2yo/H29zS0GAAAAaMYITh6MiSEAAAAAz0Bw8mBMDAEAAAB4BoKTh6qw2bU5M18SE0MAAAAAZiM4eajt2YUqq7Qr1N9HiRFBZpcDAAAANGsEJw91cmKInvEt5OVlMbcYAAAAoJkjOHkoJoYAAAAAPAfByUMxMQQAAADgOQhOHqigtEK7DxdJYmIIAAAAwBMQnDzQpgP5MgypTcsARQZbzS4HAAAAaPYITh5owykTQwAAAAAwH8HJA50MTucTnAAAAACPQHDyMIZhMOIEAAAAeBiCk4fJyi/V4cIyeXtZlBwXZnY5AAAAAERw8jgnR5s6x4QowM/b3GIAAAAASCI4eRwu0wMAAAA8D8HJw5wMTr0ITgAAAIDHMD04zZgxQ4mJifL391dKSoqWLVt22n0///xzXXHFFWrVqpVCQ0PVr18/ffvttw1YrXtV2uzadCBfEjPqAQAAAJ7E1OA0d+5cTZgwQU8++aTWr1+vQYMGaejQoUpPT691/6VLl+qKK67Q/PnztW7dOl166aW65pprtH79+gau3D125hTpeIVNwVYfJbUKNrscAAAAACdYDMMwzPrwPn36qHfv3kpLS3O0denSRSNHjtTUqVPrdY5u3bpp1KhRevrpp+u1f0FBgcLCwpSfn6/Q0NCzqttdPv4xXZM+36T+7SP0j7v7ml0OAAAA0KQ5kw1MG3EqLy/XunXrNHjw4GrtgwcP1sqVK+t1DrvdrsLCQoWHh592n7KyMhUUFFR7eKoN6cckMTEEAAAA4Gl8zPrg3Nxc2Ww2RUdHV2uPjo5WdnZ2vc7xyiuvqLi4WDfccMNp95k6daqeffbZc6rV3do9/p9q79O+362073dLkva9eJUZJQEAAAA4hemTQ1gslmrvDcOo0Vabjz/+WM8884zmzp2rqKio0+43adIk5efnOx4ZGRnnXDMAAACA5sW0EafIyEh5e3vXGF3KycmpMQr1W3PnztWdd96pzz77TL/73e/OuK/VapXVaj3negEAAAA0X6aNOPn5+SklJUULFy6s1r5w4UL179//tMd9/PHHGjt2rP7xj3/oqqu4jA0AAACA+5k24iRJEydO1OjRo5Wamqp+/fpp5syZSk9P17hx4yRVXWaXmZmp2bNnS6oKTbfddpv+9re/qW/fvo7RqoCAAIWFhZn2PQAAAAA0baYGp1GjRikvL09TpkxRVlaWkpOTNX/+fCUkJEiSsrKyqq3p9Pbbb6uyslL33Xef7rvvPkf7mDFj9MEHHzR0+QAAAACaCVPXcTKDJ67j9NtZ9U7FrHoAAACAezSKdZwAAAAAoLEgOAEAAABAHQhOAAAAAFAHghMAAAAA1IHgBAAAAAB1IDgBAAAAQB0ITgAAAABQB4ITAAAAANSB4AQAAAAAdSA4AQAAAEAdCE4AAAAAUAeCEwAAAADUgeAEAAAAAHUgOAEAAABAHQhOAAAAAFAHghMAAAAA1IHgBAAAAAB1IDgBAAAAQB0ITgAAAABQB4ITAAAAANSB4AQAAAAAdSA4AQAAAEAdCE4AAAAAUAeCEwAAAADUgeAEAAAAAHUgOAEAAABAHQhOAAAAAFAHghMAAAAA1IHgBAAAAAB1IDgBAAAAQB0ITgAAAABQB4ITAAAAANSB4AQAAAAAdSA4AQAAAEAdCE4AAAAAUAeCEwAAAADUgeAEAAAAAHXwMbsA1E+7x/9zxu37XryqgSoBAAAAmh9GnAAAAACgDgQnAAAAAKgDwQkAAAAA6kBwAgAAAIA6EJwAAAAAoA4EJwAAAACoA9ORNyFMWQ4AAAC4ByNOAAAAAFAHghMAAAAA1IHgBAAAAAB1IDgBAAAAQB0ITgAAAABQB4ITAAAAANSB4AQAAAAAdSA4AQAAAEAdCE4AAAAAUAeCEwAAAADUgeAEAAAAAHXwMbsANLx2j//ntNv2vXhVA1YCAAAANA6MOAEAAABAHQhOAAAAAFAHLtVDrc50OZ/EJX0AAABoXhhxAgAAAIA6EJwAAAAAoA5cqodzwgx9AAAAaA4YcQIAAACAOjDiBLdjogkAAAA0dgQneAwu+wMAAICnIjihUWH0CgAAAGYgOKHJIVwBAADA1QhOaLa4NBAAAAD1RXACzoDRKwAAAEgEJ8AlGL0CAABo2ghOQANh9AoAAKDxIjgBHoRwBQAA4JkITkAjVJ9LAwlhAAAArkNwApo57s8CAACoG8EJQJ0YvQIAAM0dwQmAy7jqEkKCGgAA8DSmB6cZM2bor3/9q7KystStWzdNnz5dgwYNOu3+S5Ys0cSJE7VlyxbFxcXpscce07hx4xqwYgCewpX3enHJIgAAOBNTg9PcuXM1YcIEzZgxQwMGDNDbb7+toUOHauvWrWrbtm2N/ffu3athw4bp7rvv1kcffaQVK1bo3nvvVatWrXTdddeZ8A0ANCeuDGFM8AEAQONianCaNm2a7rzzTt11112SpOnTp+vbb79VWlqapk6dWmP/t956S23bttX06dMlSV26dNHatWv18ssvE5wANFsNPfLmysstPbH2+p4LANC8mBacysvLtW7dOj3++OPV2gcPHqyVK1fWesyqVas0ePDgam1DhgzRrFmzVFFRIV9f3xrHlJWVqayszPE+Pz9fklRQUHCuX8Fl7GUlp912ss4z7XNyv/rs48rP89RzUTt/hs5+nqedqzHXfnK/xlx7fc+VPPnbM55r87ND6rVPXeeqzz7uOFdjrt2V52rMtQOo28m/0w3DqHtnwySZmZmGJGPFihXV2l944QWjU6dOtR7TsWNH44UXXqjWtmLFCkOScfDgwVqPmTx5siGJBw8ePHjw4MGDBw8ePGp9ZGRk1JlfTJ8cwmKxVHtvGEaNtrr2r639pEmTJmnixImO93a7XUeOHFFERMQZP8cMBQUFio+PV0ZGhkJDQ80up1mh781Bv5uDfjcH/W4O+t089L056HfnGIahwsJCxcXF1bmvacEpMjJS3t7eys7Ortaek5Oj6OjoWo+JiYmpdX8fHx9FRETUeozVapXVaq3W1qJFi7MvvAGEhobyg24S+t4c9Ls56Hdz0O/moN/NQ9+bg36vv7CwsHrt5+XmOk7Lz89PKSkpWrhwYbX2hQsXqn///rUe069fvxr7L1iwQKmpqbXe3wQAAAAArmBacJKkiRMn6t1339V7772nbdu26aGHHlJ6erpjXaZJkybptttuc+w/btw47d+/XxMnTtS2bdv03nvvadasWXrkkUfM+goAAAAAmgFT73EaNWqU8vLyNGXKFGVlZSk5OVnz589XQkKCJCkrK0vp6emO/RMTEzV//nw99NBDevPNNxUXF6fXXnutyUxFbrVaNXny5BqXFsL96Htz0O/moN/NQb+bg343D31vDvrdfSyGUZ+59wAAAACg+TL1Uj0AAAAAaAwITgAAAABQB4ITAAAAANSB4AQAAAAAdSA4eZAZM2YoMTFR/v7+SklJ0bJly8wuqUlZunSprrnmGsXFxclisejLL7+stt0wDD3zzDOKi4tTQECALrnkEm3ZssWcYpuQqVOn6oILLlBISIiioqI0cuRIbd++vdo+9L3rpaWlqUePHo4FEPv166dvvvnGsZ0+bxhTp06VxWLRhAkTHG30vXs888wzslgs1R4xMTGO7fS7+2RmZurWW29VRESEAgMD1atXL61bt86xnb53vXbt2tX4ebdYLLrvvvsk0efuQnDyEHPnztWECRP05JNPav369Ro0aJCGDh1abTp2nJvi4mL17NlTb7zxRq3bX3rpJU2bNk1vvPGG1qxZo5iYGF1xxRUqLCxs4EqbliVLlui+++7T6tWrtXDhQlVWVmrw4MEqLi527EPfu16bNm304osvau3atVq7dq0uu+wyjRgxwvEPJ33ufmvWrNHMmTPVo0ePau30vft069ZNWVlZjsemTZsc2+h39zh69KgGDBggX19fffPNN9q6dateeeUVtWjRwrEPfe96a9asqfazvnDhQknS9ddfL4k+dxsDHuHCCy80xo0bV62tc+fOxuOPP25SRU2bJOOLL75wvLfb7UZMTIzx4osvOtpKS0uNsLAw46233jKhwqYrJyfHkGQsWbLEMAz6viG1bNnSePfdd+nzBlBYWGh07NjRWLhwoXHxxRcb48ePNwyDn3d3mjx5stGzZ89at9Hv7vOnP/3JGDhw4Gm30/cNY/z48Ub79u0Nu91On7sRI04eoLy8XOvWrdPgwYOrtQ8ePFgrV640qarmZe/evcrOzq72Z2C1WnXxxRfzZ+Bi+fn5kqTw8HBJ9H1DsNls+uSTT1RcXKx+/frR5w3gvvvu01VXXaXf/e531drpe/fauXOn4uLilJiYqBtvvFF79uyRRL+701dffaXU1FRdf/31ioqK0vnnn6933nnHsZ2+d7/y8nJ99NFHuuOOO2SxWOhzNyI4eYDc3FzZbDZFR0dXa4+OjlZ2drZJVTUvJ/uZPwP3MgxDEydO1MCBA5WcnCyJvnenTZs2KTg4WFarVePGjdMXX3yhrl270udu9sknn+inn37S1KlTa2yj792nT58+mj17tr799lu98847ys7OVv/+/ZWXl0e/u9GePXuUlpamjh076ttvv9W4ceP04IMPavbs2ZL4mW8IX375pY4dO6axY8dKos/dycfsAvAri8VS7b1hGDXa4F78GbjX/fffr59//lnLly+vsY2+d73zzjtPGzZs0LFjxzRv3jyNGTNGS5YscWynz10vIyND48eP14IFC+Tv73/a/eh71xs6dKjjdffu3dWvXz+1b99eH374ofr27SuJfncHu92u1NRU/eUvf5EknX/++dqyZYvS0tJ02223Ofaj791n1qxZGjp0qOLi4qq10+eux4iTB4iMjJS3t3eN/wuQk5NT4/8WwD1OzrzEn4H7PPDAA/rqq6+0ePFitWnTxtFO37uPn5+fOnTooNTUVE2dOlU9e/bU3/72N/rcjdatW6ecnBylpKTIx8dHPj4+WrJkiV577TX5+Pg4+pe+d7+goCB1795dO3fu5GfejWJjY9W1a9dqbV26dHFMbkXfu9f+/fv1v//9T3fddZejjT53H4KTB/Dz81NKSopjRpSTFi5cqP79+5tUVfOSmJiomJiYan8G5eXlWrJkCX8G58gwDN1///36/PPP9d133ykxMbHadvq+4RiGobKyMvrcjS6//HJt2rRJGzZscDxSU1N1yy23aMOGDUpKSqLvG0hZWZm2bdum2NhYfubdaMCAATWWmNixY4cSEhIk8Xe8u73//vuKiorSVVdd5Wijz93IpEkp8BuffPKJ4evra8yaNcvYunWrMWHCBCMoKMjYt2+f2aU1GYWFhcb69euN9evXG5KMadOmGevXrzf2799vGIZhvPjii0ZYWJjx+eefG5s2bTJuuukmIzY21igoKDC58sbtnnvuMcLCwozvv//eyMrKcjxKSkoc+9D3rjdp0iRj6dKlxt69e42ff/7ZeOKJJwwvLy9jwYIFhmHQ5w3p1Fn1DIO+d5eHH37Y+P777409e/YYq1evNq6++mojJCTE8e8o/e4eP/74o+Hj42O88MILxs6dO405c+YYgYGBxkcffeTYh753D5vNZrRt29b405/+VGMbfe4eBCcP8uabbxoJCQmGn5+f0bt3b8d0zXCNxYsXG5JqPMaMGWMYRtWUqZMnTzZiYmIMq9VqXHTRRcamTZvMLboJqK3PJRnvv/++Yx/63vXuuOMOx98nrVq1Mi6//HJHaDIM+rwh/TY40ffuMWrUKCM2Ntbw9fU14uLijN///vfGli1bHNvpd/f5+uuvjeTkZMNqtRqdO3c2Zs6cWW07fe8e3377rSHJ2L59e41t9Ll7WAzDMEwZ6gIAAACARoJ7nAAAAACgDgQnAAAAAKgDwQkAAAAA6kBwAgAAAIA6EJwAAAAAoA4EJwAAAACoA8EJAAAAAOpAcAIAnNYll1yiCRMmuOx8zzzzjHr16uWy80nSvn37ZLFYtGHDBpeeFwCAUxGcAKAZGDt2rCwWiywWi3x9fZWUlKRHHnlExcXFZzzu888/13PPPeeyOh555BEtWrTIZeeD67Rr107Tp083uwwA8Fg+ZhcAAGgYV155pd5//31VVFRo2bJluuuuu1RcXKy0tLQa+1ZUVMjX11fh4eEurSE4OFjBwcEuPScAAA2BEScAaCasVqtiYmIUHx+vm2++Wbfccou+/PJLSb9eQvfee+8pKSlJVqtVhmHUuFSvXbt2+stf/qI77rhDISEhatu2rWbOnFntcw4cOKAbb7xR4eHhCgoKUmpqqn744Ydqn3PS2LFjNXLkSD377LOKiopSaGio/vjHP6q8vNyxz3//+18NHDhQLVq0UEREhK6++mrt3r3bqe9eVlamxx57TPHx8bJarerYsaNmzZrl2L5kyRJdeOGFslqtio2N1eOPP67KykrH9ksuuUQPPPCAJkyYoJYtWyo6OlozZ85UcXGxbr/9doWEhKh9+/b65ptvHMd8//33slgs+s9//qOePXvK399fffr00aZNm6rVNm/ePHXr1k1Wq1Xt2rXTK6+8Um17ffo8MzNTo0aNUsuWLRUREaERI0Zo3759Nfr55ZdfVmxsrCIiInTfffepoqLC8f3279+vhx56yDEyCQCojuAEAM1UQECA4xdnSdq1a5c+/fRTzZs374z3C73yyitKTU3V+vXrde+99+qee+7RL7/8IkkqKirSxRdfrIMHD+qrr77Sxo0b9dhjj8lut5/2fIsWLdK2bdu0ePFiffzxx/riiy/07LPPOrYXFxdr4sSJWrNmjRYtWiQvLy9de+21Zzznb91222365JNP9Nprr2nbtm166623HCNfmZmZGjZsmC644AJt3LhRaWlpmjVrlp5//vlq5/jwww8VGRmpH3/8UQ888IDuueceXX/99erfv79++uknDRkyRKNHj1ZJSUm14x599FG9/PLLWrNmjaKiojR8+HBHv69bt0433HCDbrzxRm3atEnPPPOMnnrqKX3wwQf17vOSkhJdeumlCg4O1tKlS7V8+XIFBwfryiuvrBZAFy9erN27d2vx4sX68MMP9cEHHzg+5/PPP1ebNm00ZcoUZWVlKSsrq959CwDNhgEAaPLGjBljjBgxwvH+hx9+MCIiIowbbrjBMAzDmDx5suHr62vk5ORUO+7iiy82xo8f73ifkJBg3HrrrY73drvdiIqKMtLS0gzDMIy3337bCAkJMfLy8mqtY/LkyUbPnj2r1RUeHm4UFxc72tLS0ozg4GDDZrPVeo6cnBxDkrFp0ybDMAxj7969hiRj/fr1te6/fft2Q5KxcOHCWrc/8cQTxnnnnWfY7XZH25tvvlmthosvvtgYOHCgY3tlZaURFBRkjB492tGWlZVlSDJWrVplGIZhLF682JBkfPLJJ4598vLyjICAAGPu3LmGYRjGzTffbFxxxRXV6nn00UeNrl27Ot7X1eezZs2qUX9ZWZkREBBgfPvtt4ZhVPVzQkKCUVlZ6djn+uuvN0aNGlXtc1599dVa+wgAYBiMOAFAM/Hvf/9bwcHB8vf3V79+/XTRRRfp9ddfd2xPSEhQq1at6jxPjx49HK8tFotiYmKUk5MjSdqwYYPOP/98p+6N6tmzpwIDAx3v+/Xrp6KiImVkZEiSdu/erZtvvllJSUkKDQ1VYmKiJCk9Pb1e59+wYYO8vb118cUX17p927Zt6tevX7XL0wYMGKCioiIdOHDA0Xbq9/b29lZERIS6d+/uaIuOjpYkR1+c+n1OCg8P13nnnadt27Y5PnvAgAHV9h8wYIB27twpm81W62f/ts/XrVunXbt2KSQkxHEPWXh4uEpLS6td0titWzd5e3s73sfGxtaoFQBwekwOAQDNxKWXXqq0tDT5+voqLi5Ovr6+1bYHBQXV6zy/Pc5isTgumwsICHBNsSfOK0nXXHON4uPj9c477yguLk52u13JycnVLkM7k7pqMgyjxj09hmFUq0Gq/Xuf2nZy3/pcQnhy3zN99qnO1Od2u10pKSmaM2dOjeNODcJnOgcAoG6MOAFAMxEUFKQOHTooISGhxi/RrtKjRw9t2LBBR44cqfcxGzdu1PHjxx3vV69ereDgYLVp00Z5eXnatm2b/vznP+vyyy9Xly5ddPToUadq6t69u+x2u5YsWVLr9q5du2rlypXVAsvKlSsVEhKi1q1bO/VZtVm9erXj9dGjR7Vjxw517tzZ8dnLly+vtv/KlSvVqVOnaqNDZ9K7d2/t3LlTUVFR6tChQ7VHWFhYvev08/OrNsoFAKiO4AQAcJmbbrpJMTExGjlypFasWKE9e/Zo3rx5WrVq1WmPKS8v15133qmtW7fqm2++0eTJk3X//ffLy8vLMUvczJkztWvXLn333XeaOHGiUzW1a9dOY8aM0R133KEvv/xSe/fu1ffff69PP/1UknTvvfcqIyNDDzzwgH755Rf961//0uTJkzVx4kR5eZ37P5NTpkzRokWLtHnzZo0dO1aRkZEaOXKkJOnhhx/WokWL9Nxzz2nHjh368MMP9cYbb+iRRx6p9/lvueUWRUZGasSIEVq2bJn27t2rJUuWaPz48dUuNaxLu3bttHTpUmVmZio3N9fZrwkATR7BCQDgMn5+flqwYIGioqI0bNgwde/eXS+++OIZR08uv/xydezYURdddJFuuOEGXXPNNXrmmWckSV5eXvrkk0+0bt06JScn66GHHtJf//pXp+tKS0vTH/7wB917773q3Lmz7r77bsfiv61bt9b8+fP1448/qmfPnho3bpzuvPNO/fnPfz6rPvitF198UePHj1dKSoqysrL01Vdfyc/PT1LVaNGnn36qTz75RMnJyXr66ac1ZcoUjR07tt7nDwwM1NKlS9W2bVv9/ve/V5cuXXTHHXfo+PHjCg0Nrfd5pkyZon379ql9+/b1utcNAJobi1HbxdQAADSAsWPH6tixY471pJqS77//XpdeeqmOHj2qFi1amF0OAOAcMeIEAAAAAHUgOAEAAABAHbhUDwAAAADqwIgTAAAAANSB4AQAAAAAdSA4AQAAAEAdCE4AAAAAUAeCEwAAAADUgeAEAAAAAHUgOAEAAABAHQhOAAAAAFAHghMAAAAA1OH/A4oPuikRIB2oAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Numerical Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning & Statistics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Jupyter Notebook Imports\n",
    "import import_ipynb\n",
    "\n",
    "# PyTorch & Deep Learning Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Custom Modules\n",
    "from phased_lstm_implementation import PLSTM, Model\n",
    "from feature_engineering import scaler_y\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "import optuna\n",
    "from optuna.pruners import HyperbandPruner\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed \n",
    "SEED = 42\n",
    "\n",
    "def set_seed():\n",
    "\n",
    "    # PyTorch Seed\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "    # NumPy Seed\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    # Python random seed\n",
    "    random.seed(SEED)\n",
    "    # Determinismus erzwingen\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # Keine automatische Optimierung\n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "set_seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Import \n",
    "\n",
    "# Load X_train\n",
    "with open(\"data/X_train.pkl\", \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "# Load y_train\n",
    "with open(\"data/y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "# Load X_val\n",
    "with open(\"data/X_val.pkl\", \"rb\") as f:\n",
    "    X_val = pickle.load(f)\n",
    "\n",
    "# Load y_val\n",
    "with open(\"data/y_val.pkl\", \"rb\") as f:\n",
    "    y_val = pickle.load(f)\n",
    "\n",
    "# Load X_test\n",
    "with open(\"data/X_test.pkl\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "# Load y_test\n",
    "with open(\"data/y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "# Load df_final_viz\n",
    "with open(\"data/df_final_viz.pkl\", \"rb\") as f:\n",
    "    df_final_viz = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch uses: 11 Threads\n"
     ]
    }
   ],
   "source": [
    "# Setting the Number of CPU Threads in PyTorch\n",
    "num_threads = max(1, os.cpu_count() // 2)\n",
    "torch.set_num_threads(num_threads)\n",
    "print(f\"PyTorch uses: {torch.get_num_threads()} Threads\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create TensorDataset for train, validation, and test sets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "#Reproduzierbare Ergebnisse --> wei√ü noch nicht wann das was bringt??\n",
    "def seed_worker(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "    torch.manual_seed(SEED + worker_id)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "\n",
    "#DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=False, num_workers=0)#, worker_init_fn=seed_worker)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=False, num_workers=0)#, worker_init_fn=seed_worker, )\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=False, num_workers=0)#, worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27024, 24, 17])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model runs on: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = False\n",
    "\n",
    "if USE_GPU and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Model runs on: {device}\")\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hp):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hp['rnn_units'], batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(hp['dropout_rate_rnn'])\n",
    "        self.fc1 = nn.Linear(hp['rnn_units'], hp['dense_units'])\n",
    "        self.dropout2 = nn.Dropout(hp['dropout_rate_dense'])\n",
    "        self.fc2 = nn.Linear(hp['dense_units'], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]  # Nur der letzte Zeitschritt\n",
    "        out = self.dropout1(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 17:45:07,193] A new study created in memory with name: no-name-46bbc8ed-c8c9-4087-b5ac-c9aaa7a4e6f9\n",
      "[I 2025-04-03 17:48:50,572] Trial 0 finished with value: 0.0012779219043441118 and parameters: {'rnn_units': 192, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 32, 'dropout_rate_dense': 0.1, 'learning_rate': 0.01, 'weight_decay': 0.001}. Best is trial 0 with value: 0.0012779219043441118.\n",
      "[I 2025-04-03 17:50:22,226] Trial 1 finished with value: 0.002648130712332204 and parameters: {'rnn_units': 208, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 32, 'dropout_rate_dense': 0.30000000000000004, 'learning_rate': 0.01, 'weight_decay': 1e-05}. Best is trial 0 with value: 0.0012779219043441118.\n",
      "[W 2025-04-03 17:52:02,037] Trial 2 failed with parameters: {'rnn_units': 144, 'dropout_rate_rnn': 0.1, 'dense_units': 16, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.001} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\veren\\AppData\\Local\\Temp\\ipykernel_66024\\3799411321.py\", line 32, in objective\n",
      "    loss.backward()\n",
      "  File \"c:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\torch\\_tensor.py\", line 525, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"c:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 267, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"c:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\torch\\autograd\\graph.py\", line 744, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-03 17:52:02,038] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m pruner \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mHyperbandPruner(min_resource\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, max_resource\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, reduction_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     69\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, pruner\u001b[38;5;241m=\u001b[39mpruner)\n\u001b[1;32m---> 70\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Show Best Result\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[53], line 32\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     30\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rnn_model(X_batch)\n\u001b[0;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y_batch)\n\u001b[1;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     34\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Objective-function with Hyperband-Pruning for RNN\n",
    "def objective(trial):\n",
    "    hp = {\n",
    "        'rnn_units': trial.suggest_int('rnn_units', 32, 256, step=16),\n",
    "        'dropout_rate_rnn': trial.suggest_float('dropout_rate_rnn', 0.1, 0.5, step=0.1),\n",
    "        'dense_units': trial.suggest_int('dense_units', 8, 64, step=8),\n",
    "        'dropout_rate_dense': trial.suggest_float('dropout_rate_dense', 0.0, 0.4, step=0.1),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "    }\n",
    "\n",
    "    set_seed()\n",
    "    \n",
    "    rnn_model = SimpleRNN(input_size=X_train.shape[2], hp=hp).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(rnn_model.parameters(), lr=hp['learning_rate'])\n",
    "\n",
    "    num_epochs = 15\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        rnn_model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = rnn_model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        rnn_model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                y_pred = rnn_model(X_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # Optuna-Pruning Check\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        # Early Stopping Check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                break\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "# Study with HyperbandPruner\n",
    "sampler = optuna.samplers.TPESampler(seed=SEED) \n",
    "pruner = optuna.pruners.HyperbandPruner(min_resource=3, max_resource=15, reduction_factor=3)\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=10, n_jobs=1)\n",
    "\n",
    "# Show Best Result\n",
    "print(\"Best trial parameters:\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best hyperparameters\n",
    "best_hp = study.best_trial.params\n",
    "with open(\"best_hp_all_models/best_hp_rnn.json\", \"w\") as f:\n",
    "    json.dump(best_hp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best hyperparameters \n",
    "with open(\"best_hp_all_models/best_hp_rnn.json\", \"r\") as f:\n",
    "    best_hp = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.0045, Val Loss: 0.0015\n",
      "Epoch [2/50], Train Loss: 0.0018, Val Loss: 0.0008\n",
      "Epoch [3/50], Train Loss: 0.0014, Val Loss: 0.0011\n",
      "Epoch [4/50], Train Loss: 0.0012, Val Loss: 0.0015\n",
      "Epoch [5/50], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [6/50], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [7/50], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [8/50], Train Loss: 0.0011, Val Loss: 0.0007\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m     32\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m final_model(X_batch)\n\u001b[0;32m     33\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y_batch)\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\veren\\anaconda3\\envs\\ep_forecasting_env\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Bestes Modell mit den gefundenen Hyperparametern trainieren\n",
    "set_seed()\n",
    "\n",
    "final_model = SimpleRNN(input_size=X_train.shape[2], hp=best_hp)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=best_hp['learning_rate'])\n",
    "\n",
    "num_epochs = 50\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "patience = 10\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    final_model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = final_model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_history.append(train_loss)\n",
    "\n",
    "    # Validation Loss berechnen\n",
    "    final_model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            y_pred = final_model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    val_loss_history.append(val_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0  # Reset Counter\n",
    "        torch.save(final_model.state_dict(), \"saved_models/rnn_model_final.pth\") #save best weights\n",
    "\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f\"Early stopping nach {epoch+1} Epochen.\")\n",
    "            break\n",
    "\n",
    "# **Trainingshistorie plotten**\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss_history, label=\"Train Loss\")\n",
    "plt.plot(val_loss_history, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epochen\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Trainings- und Validierungsverlust\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleRNN(\n",
       "  (rnn): RNN(17, 112, batch_first=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=112, out_features=48, bias=True)\n",
       "  (dropout2): Dropout(p=0.0, inplace=False)\n",
       "  (fc2): Linear(in_features=48, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained model  \n",
    "rnn_final = SimpleRNN(input_size=X_train.shape[2], hp=best_hp)\n",
    "rnn_final.load_state_dict(torch.load(\"saved_models/rnn_model_final.pth\"))\n",
    "rnn_final.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engineering import scaler_y\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Make predictions\n",
    "def get_predictions_in_batches(model, X_tensor, batch_size=128):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_tensor), batch_size):\n",
    "            batch = X_tensor[i:i+batch_size]\n",
    "            preds.append(model(batch).numpy()) \n",
    "    return np.vstack(preds)\n",
    "\n",
    "train_predictions = get_predictions_in_batches(rnn_final, X_train_tensor)\n",
    "validation_predictions = get_predictions_in_batches(rnn_final, X_val_tensor)\n",
    "test_predictions = get_predictions_in_batches(rnn_final, X_test_tensor)\n",
    "\n",
    "# Inverse transform scaled predictions and scaled target\n",
    "train_predictions_actual = scaler_y.inverse_transform(train_predictions)\n",
    "validation_predictions_actual = scaler_y.inverse_transform(validation_predictions)\n",
    "test_predictions_actual = scaler_y.inverse_transform(test_predictions)\n",
    "\n",
    "y_train_actual = scaler_y.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_val_actual = scaler_y.inverse_transform(y_val.reshape(-1, 1))\n",
    "y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate loss on original scale\n",
    "mse_train = mean_squared_error(y_train_actual, train_predictions_actual)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "\n",
    "mse_val = mean_squared_error(y_val_actual, validation_predictions_actual)\n",
    "rmse_val = np.sqrt(mse_val)\n",
    "\n",
    "mse_test = mean_squared_error(y_test_actual, test_predictions_actual)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "print(f\"Original Train MSE: {mse_train:.4f}, Original Train RMSE: {rmse_train:.4f}\")\n",
    "print(f\"Original Validation MSE: {mse_val:.4f}, Original Validation RMSE: {rmse_val:.4f}\")\n",
    "print(f\"Original Test MSE: {mse_test:.4f}, Original Test RMSE: {rmse_test:.4f}\")\n",
    "\n",
    "# Calculate loss on scaled test data\n",
    "mse_test_scaled = mean_squared_error(y_test_tensor, test_predictions)\n",
    "rmse_test_scaled = np.sqrt(mse_test_scaled)\n",
    "print(f\"Scaled Test MSE: {mse_test_scaled:.4f}, Scaled Test RMSE: {rmse_test_scaled:.4f}\")\n",
    "\n",
    "# Plot of the forecast\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot of actual values\n",
    "seq_length = 24 ################################# hier √§nder wenn sich sequenz √§ndert!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "plt.plot(df_final_viz.index[seq_length:], df_final_viz['price actual'][seq_length:], label='Actual', color='blue')\n",
    "\n",
    "# Training predictions\n",
    "train_start = seq_length\n",
    "train_end = train_start + len(train_predictions_actual)\n",
    "plt.plot(df_final_viz.index[train_start:train_end], train_predictions_actual, label='Train Predictions', color='green', alpha=0.8)\n",
    "\n",
    "# Validation predictions \n",
    "val_start = train_end + seq_length\n",
    "val_end = val_start + len(validation_predictions_actual)\n",
    "plt.plot(df_final_viz.index[val_start:val_end], validation_predictions_actual, label='Validation Predictions', color='red', alpha=0.8)\n",
    "\n",
    "# Test predictions \n",
    "test_start = val_end + seq_length\n",
    "test_end = test_start + len(test_predictions_actual)\n",
    "plt.plot(df_final_viz.index[test_start:test_end], test_predictions_actual, label='Test Predictions', color='orange', alpha=0.8)\n",
    "\n",
    "plt.title('Electricity Price Time Series Forecasting (RNN)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0: torch.Size([240, 17])\n",
      "rnn.weight_hh_l0: torch.Size([240, 240])\n",
      "rnn.bias_ih_l0: torch.Size([240])\n",
      "rnn.bias_hh_l0: torch.Size([240])\n",
      "fc1.weight: torch.Size([8, 240])\n",
      "fc1.bias: torch.Size([8])\n",
      "fc2.weight: torch.Size([1, 8])\n",
      "fc2.bias: torch.Size([1])\n",
      "Total number of model paramters RNN: 64,097\n"
     ]
    }
   ],
   "source": [
    "for name, param in rnn_final.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")\n",
    "    \n",
    "total_params = sum(p.numel() for p in rnn_final.parameters())\n",
    "print(f\"Total number of model paramters RNN: {total_params:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ep_forecasting_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
