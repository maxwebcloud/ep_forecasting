{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ep_forecasting_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sympy import false, true\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Import \n",
    "\n",
    "# Load X_train\n",
    "with open(\"data/X_train.pkl\", \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "# Load y_train\n",
    "with open(\"data/y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "# Load X_val\n",
    "with open(\"data/X_val.pkl\", \"rb\") as f:\n",
    "    X_val = pickle.load(f)\n",
    "\n",
    "# Load y_val\n",
    "with open(\"data/y_val.pkl\", \"rb\") as f:\n",
    "    y_val = pickle.load(f)\n",
    "\n",
    "# Load X_test\n",
    "with open(\"data/X_test.pkl\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "# Load y_test\n",
    "with open(\"data/y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "# Load df_final_viz\n",
    "with open(\"data/df_final_viz.pkl\", \"rb\") as f:\n",
    "    df_final_viz = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch nutzt 8 Threads\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(torch.get_num_threads())  # Nutzt standardmäßig alle verfügbaren Kerne\n",
    "print(f\"PyTorch nutzt {torch.get_num_threads()} Threads\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Torch-Tensoren umwandeln\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Datasets und DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last = True, num_workers = 8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last = True, num_workers = 8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last = True, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27024"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hp):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hp['rnn_units'], batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(hp['dropout_rate_rnn'])\n",
    "        self.fc1 = nn.Linear(hp['rnn_units'], hp['dense_units'])\n",
    "        self.dropout2 = nn.Dropout(hp['dropout_rate_dense'])\n",
    "        self.fc2 = nn.Linear(hp['dense_units'], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]  # Nur der letzte Zeitschritt\n",
    "        out = self.dropout1(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 12:51:48,366] A new study created in memory with name: no-name-48d7f4e7-1f3d-4e65-bef0-4f6e46c9807d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.0056, Val Loss: 0.0028\n",
      "Epoch [2/15], Train Loss: 0.0026, Val Loss: 0.0031\n",
      "Epoch [3/15], Train Loss: 0.0028, Val Loss: 0.0026\n",
      "Epoch [4/15], Train Loss: 0.0029, Val Loss: 0.0018\n",
      "Epoch [1/15], Train Loss: 0.0080, Val Loss: 0.0019\n",
      "Epoch [1/15], Train Loss: 0.0221, Val Loss: 0.0066\n",
      "Epoch [1/15], Train Loss: 0.0210, Val Loss: 0.0045\n",
      "Epoch [1/15], Train Loss: 0.0029, Val Loss: 0.0019\n",
      "Epoch [1/15], Train Loss: 0.0119, Val Loss: 0.0018\n",
      "Epoch [5/15], Train Loss: 0.0029, Val Loss: 0.0016\n",
      "Epoch [1/15], Train Loss: 0.0034, Val Loss: 0.0011\n",
      "Epoch [1/15], Train Loss: 0.0044, Val Loss: 0.0017\n",
      "Epoch [6/15], Train Loss: 0.0030, Val Loss: 0.0028\n",
      "Epoch [7/15], Train Loss: 0.0030, Val Loss: 0.0026\n",
      "Epoch [8/15], Train Loss: 0.0030, Val Loss: 0.0021\n",
      "Epoch [9/15], Train Loss: 0.0030, Val Loss: 0.0022\n",
      "Epoch [2/15], Train Loss: 0.0029, Val Loss: 0.0011\n",
      "Epoch [2/15], Train Loss: 0.0069, Val Loss: 0.0027\n",
      "Epoch [2/15], Train Loss: 0.0057, Val Loss: 0.0021\n",
      "Epoch [2/15], Train Loss: 0.0014, Val Loss: 0.0014\n",
      "Epoch [2/15], Train Loss: 0.0019, Val Loss: 0.0010\n",
      "Epoch [2/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [10/15], Train Loss: 0.0030, Val Loss: 0.0019\n",
      "Epoch [2/15], Train Loss: 0.0020, Val Loss: 0.0012\n",
      "Epoch [11/15], Train Loss: 0.0030, Val Loss: 0.0012\n",
      "Epoch [12/15], Train Loss: 0.0030, Val Loss: 0.0016\n",
      "Epoch [13/15], Train Loss: 0.0029, Val Loss: 0.0021\n",
      "Epoch [14/15], Train Loss: 0.0030, Val Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 12:54:19,079] Trial 1 finished with value: 0.0010795074166737558 and parameters: {'rnn_units': 16, 'dropout_rate_rnn': 0.2, 'dense_units': 48, 'dropout_rate_dense': 0.4, 'learning_rate': 0.01, 'weight_decay': 0.001}. Best is trial 1 with value: 0.0010795074166737558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0031, Val Loss: 0.0011\n",
      "Epoch [3/15], Train Loss: 0.0018, Val Loss: 0.0007\n",
      "Epoch [3/15], Train Loss: 0.0049, Val Loss: 0.0023\n",
      "Epoch [3/15], Train Loss: 0.0045, Val Loss: 0.0018\n",
      "Epoch [3/15], Train Loss: 0.0013, Val Loss: 0.0009\n",
      "Epoch [3/15], Train Loss: 0.0017, Val Loss: 0.0008\n",
      "Epoch [3/15], Train Loss: 0.0010, Val Loss: 0.0008\n",
      "Epoch [3/15], Train Loss: 0.0016, Val Loss: 0.0015\n",
      "Epoch [1/15], Train Loss: 0.0349, Val Loss: 0.0056\n",
      "Epoch [4/15], Train Loss: 0.0014, Val Loss: 0.0007\n",
      "Epoch [4/15], Train Loss: 0.0039, Val Loss: 0.0019\n",
      "Epoch [4/15], Train Loss: 0.0039, Val Loss: 0.0017\n",
      "Epoch [4/15], Train Loss: 0.0013, Val Loss: 0.0010\n",
      "Epoch [4/15], Train Loss: 0.0017, Val Loss: 0.0011\n",
      "Epoch [4/15], Train Loss: 0.0009, Val Loss: 0.0008\n",
      "Epoch [4/15], Train Loss: 0.0015, Val Loss: 0.0011\n",
      "Epoch [2/15], Train Loss: 0.0100, Val Loss: 0.0019\n",
      "Epoch [5/15], Train Loss: 0.0013, Val Loss: 0.0007\n",
      "Epoch [5/15], Train Loss: 0.0033, Val Loss: 0.0023\n",
      "Epoch [5/15], Train Loss: 0.0035, Val Loss: 0.0017\n",
      "Epoch [5/15], Train Loss: 0.0013, Val Loss: 0.0009\n",
      "Epoch [5/15], Train Loss: 0.0018, Val Loss: 0.0015\n",
      "Epoch [5/15], Train Loss: 0.0009, Val Loss: 0.0007\n",
      "Epoch [5/15], Train Loss: 0.0014, Val Loss: 0.0011\n",
      "Epoch [6/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [3/15], Train Loss: 0.0079, Val Loss: 0.0016\n",
      "Epoch [6/15], Train Loss: 0.0028, Val Loss: 0.0017\n",
      "Epoch [6/15], Train Loss: 0.0031, Val Loss: 0.0014\n",
      "Epoch [6/15], Train Loss: 0.0012, Val Loss: 0.0009\n",
      "Epoch [6/15], Train Loss: 0.0019, Val Loss: 0.0014\n",
      "Epoch [6/15], Train Loss: 0.0009, Val Loss: 0.0008\n",
      "Epoch [6/15], Train Loss: 0.0014, Val Loss: 0.0010\n",
      "Epoch [7/15], Train Loss: 0.0012, Val Loss: 0.0006\n",
      "Epoch [4/15], Train Loss: 0.0070, Val Loss: 0.0015\n",
      "Epoch [7/15], Train Loss: 0.0025, Val Loss: 0.0016\n",
      "Epoch [7/15], Train Loss: 0.0028, Val Loss: 0.0015\n",
      "Epoch [7/15], Train Loss: 0.0020, Val Loss: 0.0011\n",
      "Epoch [7/15], Train Loss: 0.0013, Val Loss: 0.0010\n",
      "Epoch [7/15], Train Loss: 0.0009, Val Loss: 0.0007\n",
      "Epoch [7/15], Train Loss: 0.0014, Val Loss: 0.0009\n",
      "Epoch [8/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [8/15], Train Loss: 0.0023, Val Loss: 0.0015\n",
      "Epoch [5/15], Train Loss: 0.0063, Val Loss: 0.0020\n",
      "Epoch [8/15], Train Loss: 0.0026, Val Loss: 0.0016\n",
      "Epoch [8/15], Train Loss: 0.0020, Val Loss: 0.0014\n",
      "Epoch [8/15], Train Loss: 0.0013, Val Loss: 0.0009\n",
      "Epoch [8/15], Train Loss: 0.0009, Val Loss: 0.0007\n",
      "Epoch [8/15], Train Loss: 0.0014, Val Loss: 0.0010\n",
      "Epoch [9/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [9/15], Train Loss: 0.0020, Val Loss: 0.0017\n",
      "Epoch [6/15], Train Loss: 0.0056, Val Loss: 0.0014\n",
      "Epoch [9/15], Train Loss: 0.0024, Val Loss: 0.0013\n",
      "Epoch [9/15], Train Loss: 0.0022, Val Loss: 0.0012\n",
      "Epoch [9/15], Train Loss: 0.0013, Val Loss: 0.0009\n",
      "Epoch [9/15], Train Loss: 0.0009, Val Loss: 0.0007\n",
      "Epoch [9/15], Train Loss: 0.0014, Val Loss: 0.0012\n",
      "Epoch [10/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [10/15], Train Loss: 0.0019, Val Loss: 0.0011\n",
      "Epoch [7/15], Train Loss: 0.0050, Val Loss: 0.0015\n",
      "Epoch [10/15], Train Loss: 0.0022, Val Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 12:59:12,300] Trial 7 finished with value: 0.0008346766674461128 and parameters: {'rnn_units': 112, 'dropout_rate_rnn': 0.5, 'dense_units': 56, 'dropout_rate_dense': 0.0, 'learning_rate': 0.01, 'weight_decay': 0.0001}. Best is trial 7 with value: 0.0008346766674461128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], Train Loss: 0.0023, Val Loss: 0.0018\n",
      "Early stopping nach 10 Epochen.\n",
      "Epoch [10/15], Train Loss: 0.0013, Val Loss: 0.0010\n",
      "Epoch [1/15], Train Loss: 0.0123, Val Loss: 0.0016\n",
      "Epoch [10/15], Train Loss: 0.0009, Val Loss: 0.0010\n",
      "Epoch [2/15], Train Loss: 0.0033, Val Loss: 0.0012\n",
      "Epoch [10/15], Train Loss: 0.0014, Val Loss: 0.0009\n",
      "Epoch [3/15], Train Loss: 0.0023, Val Loss: 0.0011\n",
      "Epoch [4/15], Train Loss: 0.0019, Val Loss: 0.0008\n",
      "Epoch [11/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [5/15], Train Loss: 0.0016, Val Loss: 0.0007\n",
      "Epoch [11/15], Train Loss: 0.0018, Val Loss: 0.0012\n",
      "Epoch [6/15], Train Loss: 0.0015, Val Loss: 0.0008\n",
      "Epoch [8/15], Train Loss: 0.0046, Val Loss: 0.0013\n",
      "Epoch [11/15], Train Loss: 0.0021, Val Loss: 0.0011\n",
      "Epoch [7/15], Train Loss: 0.0014, Val Loss: 0.0008\n",
      "Epoch [11/15], Train Loss: 0.0013, Val Loss: 0.0014\n",
      "Epoch [8/15], Train Loss: 0.0014, Val Loss: 0.0007\n",
      "Epoch [11/15], Train Loss: 0.0009, Val Loss: 0.0007\n",
      "Epoch [9/15], Train Loss: 0.0014, Val Loss: 0.0007\n",
      "Epoch [11/15], Train Loss: 0.0014, Val Loss: 0.0014\n",
      "Epoch [10/15], Train Loss: 0.0013, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [11/15], Train Loss: 0.0013, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0017, Val Loss: 0.0013\n",
      "Epoch [12/15], Train Loss: 0.0013, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0020, Val Loss: 0.0014\n",
      "Epoch [9/15], Train Loss: 0.0041, Val Loss: 0.0012\n",
      "Epoch [13/15], Train Loss: 0.0013, Val Loss: 0.0006\n",
      "Epoch [12/15], Train Loss: 0.0012, Val Loss: 0.0012\n",
      "Epoch [14/15], Train Loss: 0.0013, Val Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:01:25,180] Trial 9 finished with value: 0.0006393669800966182 and parameters: {'rnn_units': 16, 'dropout_rate_rnn': 0.2, 'dense_units': 56, 'dropout_rate_dense': 0.4, 'learning_rate': 0.001, 'weight_decay': 1e-05}. Best is trial 9 with value: 0.0006393669800966182.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0013, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0009, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0014, Val Loss: 0.0014\n",
      "Epoch [13/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [13/15], Train Loss: 0.0016, Val Loss: 0.0012\n",
      "Epoch [13/15], Train Loss: 0.0019, Val Loss: 0.0011\n",
      "Epoch [10/15], Train Loss: 0.0036, Val Loss: 0.0012\n",
      "Epoch [13/15], Train Loss: 0.0012, Val Loss: 0.0010\n",
      "Epoch [1/15], Train Loss: 0.0178, Val Loss: 0.0036\n",
      "Epoch [13/15], Train Loss: 0.0009, Val Loss: 0.0007\n",
      "Epoch [13/15], Train Loss: 0.0014, Val Loss: 0.0009\n",
      "Epoch [14/15], Train Loss: 0.0012, Val Loss: 0.0006\n",
      "Epoch [14/15], Train Loss: 0.0016, Val Loss: 0.0009\n",
      "Epoch [14/15], Train Loss: 0.0018, Val Loss: 0.0010\n",
      "Epoch [11/15], Train Loss: 0.0033, Val Loss: 0.0011\n",
      "Epoch [14/15], Train Loss: 0.0012, Val Loss: 0.0009\n",
      "Epoch [2/15], Train Loss: 0.0058, Val Loss: 0.0018\n",
      "Epoch [14/15], Train Loss: 0.0009, Val Loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:02:59,304] Trial 3 finished with value: 0.0008815942814356775 and parameters: {'rnn_units': 128, 'dropout_rate_rnn': 0.1, 'dense_units': 40, 'dropout_rate_dense': 0.2, 'learning_rate': 0.001, 'weight_decay': 0.001}. Best is trial 9 with value: 0.0006393669800966182.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], Train Loss: 0.0014, Val Loss: 0.0011\n",
      "Early stopping nach 14 Epochen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:03:02,318] Trial 6 finished with value: 0.0006140163812585431 and parameters: {'rnn_units': 112, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 16, 'dropout_rate_dense': 0.2, 'learning_rate': 0.001, 'weight_decay': 1e-05}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0012, Val Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:03:09,892] Trial 4 finished with value: 0.0009394698036856191 and parameters: {'rnn_units': 80, 'dropout_rate_rnn': 0.5, 'dense_units': 56, 'dropout_rate_dense': 0.0, 'learning_rate': 0.0001, 'weight_decay': 0.001}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0015, Val Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:03:14,649] Trial 2 finished with value: 0.0009985754056082618 and parameters: {'rnn_units': 80, 'dropout_rate_rnn': 0.2, 'dense_units': 40, 'dropout_rate_dense': 0.2, 'learning_rate': 0.0001, 'weight_decay': 0.001}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0017, Val Loss: 0.0010\n",
      "Epoch [12/15], Train Loss: 0.0029, Val Loss: 0.0011\n",
      "Epoch [1/15], Train Loss: 0.1099, Val Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:03:27,332] Trial 0 finished with value: 0.000852664282231877 and parameters: {'rnn_units': 112, 'dropout_rate_rnn': 0.1, 'dense_units': 40, 'dropout_rate_dense': 0.0, 'learning_rate': 0.001, 'weight_decay': 0.001}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0012, Val Loss: 0.0009\n",
      "Early stopping nach 15 Epochen.\n",
      "Epoch [2/15], Train Loss: 0.0461, Val Loss: 0.0135\n",
      "Epoch [3/15], Train Loss: 0.0047, Val Loss: 0.0016\n",
      "Epoch [3/15], Train Loss: 0.0335, Val Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:03:47,538] Trial 5 finished with value: 0.0006246793794073915 and parameters: {'rnn_units': 128, 'dropout_rate_rnn': 0.1, 'dense_units': 64, 'dropout_rate_dense': 0.0, 'learning_rate': 0.001, 'weight_decay': 0.0001}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0009, Val Loss: 0.0006\n",
      "Epoch [1/15], Train Loss: 0.0122, Val Loss: 0.0024\n",
      "Epoch [4/15], Train Loss: 0.0269, Val Loss: 0.0099\n",
      "Epoch [1/15], Train Loss: 0.0505, Val Loss: 0.0083\n",
      "Epoch [1/15], Train Loss: 0.0308, Val Loss: 0.0042\n",
      "Epoch [5/15], Train Loss: 0.0223, Val Loss: 0.0070\n",
      "Epoch [2/15], Train Loss: 0.0133, Val Loss: 0.0061\n",
      "Epoch [1/15], Train Loss: 0.0090, Val Loss: 0.0016\n",
      "Epoch [6/15], Train Loss: 0.0182, Val Loss: 0.0054\n",
      "Epoch [13/15], Train Loss: 0.0027, Val Loss: 0.0009\n",
      "Epoch [3/15], Train Loss: 0.0092, Val Loss: 0.0052\n",
      "Epoch [7/15], Train Loss: 0.0147, Val Loss: 0.0034\n",
      "Epoch [4/15], Train Loss: 0.0062, Val Loss: 0.0031\n",
      "Epoch [1/15], Train Loss: 0.0078, Val Loss: 0.0013\n",
      "Epoch [8/15], Train Loss: 0.0120, Val Loss: 0.0033\n",
      "Epoch [5/15], Train Loss: 0.0045, Val Loss: 0.0024\n",
      "Epoch [9/15], Train Loss: 0.0100, Val Loss: 0.0028\n",
      "Epoch [4/15], Train Loss: 0.0040, Val Loss: 0.0016\n",
      "Epoch [6/15], Train Loss: 0.0037, Val Loss: 0.0021\n",
      "Epoch [10/15], Train Loss: 0.0083, Val Loss: 0.0030\n",
      "Epoch [2/15], Train Loss: 0.0048, Val Loss: 0.0021\n",
      "Epoch [7/15], Train Loss: 0.0032, Val Loss: 0.0019\n",
      "Epoch [11/15], Train Loss: 0.0070, Val Loss: 0.0021\n",
      "Epoch [2/15], Train Loss: 0.0121, Val Loss: 0.0047\n",
      "Epoch [8/15], Train Loss: 0.0030, Val Loss: 0.0018\n",
      "Epoch [12/15], Train Loss: 0.0060, Val Loss: 0.0025\n",
      "Epoch [2/15], Train Loss: 0.0017, Val Loss: 0.0009\n",
      "Epoch [9/15], Train Loss: 0.0028, Val Loss: 0.0017\n",
      "Epoch [13/15], Train Loss: 0.0052, Val Loss: 0.0020\n",
      "Epoch [14/15], Train Loss: 0.0024, Val Loss: 0.0010\n",
      "Epoch [10/15], Train Loss: 0.0026, Val Loss: 0.0016\n",
      "Epoch [14/15], Train Loss: 0.0046, Val Loss: 0.0020\n",
      "Epoch [2/15], Train Loss: 0.0029, Val Loss: 0.0018\n",
      "Epoch [11/15], Train Loss: 0.0025, Val Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:06:11,736] Trial 14 finished with value: 0.001976413135003719 and parameters: {'rnn_units': 16, 'dropout_rate_rnn': 0.2, 'dense_units': 16, 'dropout_rate_dense': 0.4, 'learning_rate': 0.0001, 'weight_decay': 0.0001}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0041, Val Loss: 0.0023\n",
      "Epoch [12/15], Train Loss: 0.0023, Val Loss: 0.0013\n",
      "Epoch [5/15], Train Loss: 0.0036, Val Loss: 0.0014\n",
      "Epoch [13/15], Train Loss: 0.0023, Val Loss: 0.0013\n",
      "Epoch [3/15], Train Loss: 0.0040, Val Loss: 0.0020\n",
      "Epoch [1/15], Train Loss: 0.0277, Val Loss: 0.0029\n",
      "Epoch [14/15], Train Loss: 0.0022, Val Loss: 0.0012\n",
      "Epoch [3/15], Train Loss: 0.0101, Val Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:06:52,028] Trial 16 finished with value: 0.0011425041686321023 and parameters: {'rnn_units': 32, 'dropout_rate_rnn': 0.4, 'dense_units': 64, 'dropout_rate_dense': 0.0, 'learning_rate': 0.0001, 'weight_decay': 0.0001}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0021, Val Loss: 0.0011\n",
      "Epoch [3/15], Train Loss: 0.0015, Val Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:06:58,396] Trial 8 finished with value: 0.0008801198357926501 and parameters: {'rnn_units': 112, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 24, 'dropout_rate_dense': 0.2, 'learning_rate': 0.0001, 'weight_decay': 1e-05}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0022, Val Loss: 0.0009\n",
      "Epoch [2/15], Train Loss: 0.0069, Val Loss: 0.0018\n",
      "Epoch [3/15], Train Loss: 0.0020, Val Loss: 0.0010\n",
      "Epoch [3/15], Train Loss: 0.0034, Val Loss: 0.0012\n",
      "Epoch [6/15], Train Loss: 0.0032, Val Loss: 0.0013\n",
      "Epoch [4/15], Train Loss: 0.0034, Val Loss: 0.0017\n",
      "Epoch [4/15], Train Loss: 0.0087, Val Loss: 0.0017\n",
      "Epoch [4/15], Train Loss: 0.0026, Val Loss: 0.0010\n",
      "Epoch [1/15], Train Loss: 0.0101, Val Loss: 0.0013\n",
      "Epoch [4/15], Train Loss: 0.0016, Val Loss: 0.0010\n",
      "Epoch [1/15], Train Loss: 0.0091, Val Loss: 0.0019\n",
      "Epoch [4/15], Train Loss: 0.0015, Val Loss: 0.0010\n",
      "Epoch [5/15], Train Loss: 0.0024, Val Loss: 0.0008\n",
      "Epoch [7/15], Train Loss: 0.0028, Val Loss: 0.0012\n",
      "Epoch [6/15], Train Loss: 0.0022, Val Loss: 0.0008\n",
      "Epoch [5/15], Train Loss: 0.0031, Val Loss: 0.0024\n",
      "Epoch [5/15], Train Loss: 0.0077, Val Loss: 0.0014\n",
      "Epoch [7/15], Train Loss: 0.0021, Val Loss: 0.0006\n",
      "Epoch [2/15], Train Loss: 0.0039, Val Loss: 0.0013\n",
      "Epoch [2/15], Train Loss: 0.0034, Val Loss: 0.0010\n",
      "Epoch [5/15], Train Loss: 0.0017, Val Loss: 0.0012\n",
      "Epoch [5/15], Train Loss: 0.0013, Val Loss: 0.0007\n",
      "Epoch [8/15], Train Loss: 0.0020, Val Loss: 0.0007\n",
      "Epoch [8/15], Train Loss: 0.0026, Val Loss: 0.0011\n",
      "Epoch [6/15], Train Loss: 0.0028, Val Loss: 0.0017\n",
      "Epoch [9/15], Train Loss: 0.0020, Val Loss: 0.0008\n",
      "Epoch [6/15], Train Loss: 0.0067, Val Loss: 0.0022\n",
      "Epoch [3/15], Train Loss: 0.0025, Val Loss: 0.0009\n",
      "Epoch [10/15], Train Loss: 0.0020, Val Loss: 0.0006\n",
      "Epoch [3/15], Train Loss: 0.0020, Val Loss: 0.0007\n",
      "Epoch [6/15], Train Loss: 0.0019, Val Loss: 0.0013\n",
      "Epoch [6/15], Train Loss: 0.0012, Val Loss: 0.0006\n",
      "Epoch [11/15], Train Loss: 0.0020, Val Loss: 0.0007\n",
      "Epoch [9/15], Train Loss: 0.0024, Val Loss: 0.0012\n",
      "Epoch [7/15], Train Loss: 0.0026, Val Loss: 0.0016\n",
      "Epoch [12/15], Train Loss: 0.0020, Val Loss: 0.0007\n",
      "Epoch [7/15], Train Loss: 0.0059, Val Loss: 0.0017\n",
      "Epoch [4/15], Train Loss: 0.0017, Val Loss: 0.0010\n",
      "Epoch [4/15], Train Loss: 0.0014, Val Loss: 0.0007\n",
      "Epoch [13/15], Train Loss: 0.0020, Val Loss: 0.0007\n",
      "Epoch [7/15], Train Loss: 0.1128, Val Loss: 0.0126\n",
      "Epoch [7/15], Train Loss: 0.0012, Val Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:10:42,420] Trial 17 finished with value: 0.0006328029518748911 and parameters: {'rnn_units': 48, 'dropout_rate_rnn': 0.4, 'dense_units': 8, 'dropout_rate_dense': 0.30000000000000004, 'learning_rate': 0.001, 'weight_decay': 1e-05}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], Train Loss: 0.0019, Val Loss: 0.0008\n",
      "Early stopping nach 14 Epochen.\n",
      "Epoch [10/15], Train Loss: 0.0022, Val Loss: 0.0012\n",
      "Epoch [8/15], Train Loss: 0.0024, Val Loss: 0.0013\n",
      "Epoch [5/15], Train Loss: 0.0014, Val Loss: 0.0007\n",
      "Epoch [8/15], Train Loss: 0.0051, Val Loss: 0.0011\n",
      "Epoch [5/15], Train Loss: 0.0013, Val Loss: 0.0009\n",
      "Epoch [8/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [8/15], Train Loss: 0.0188, Val Loss: 0.0119\n",
      "Epoch [1/15], Train Loss: 0.0061, Val Loss: 0.0013\n",
      "Epoch [11/15], Train Loss: 0.0020, Val Loss: 0.0010\n",
      "Epoch [9/15], Train Loss: 0.0022, Val Loss: 0.0017\n",
      "Epoch [6/15], Train Loss: 0.0012, Val Loss: 0.0006\n",
      "Epoch [9/15], Train Loss: 0.0045, Val Loss: 0.0012\n",
      "Epoch [6/15], Train Loss: 0.0012, Val Loss: 0.0006\n",
      "Epoch [9/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [9/15], Train Loss: 0.0148, Val Loss: 0.0106\n",
      "Epoch [2/15], Train Loss: 0.0023, Val Loss: 0.0012\n",
      "Epoch [12/15], Train Loss: 0.0019, Val Loss: 0.0009\n",
      "Epoch [10/15], Train Loss: 0.0021, Val Loss: 0.0013\n",
      "Epoch [7/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [7/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [10/15], Train Loss: 0.0039, Val Loss: 0.0011\n",
      "Epoch [10/15], Train Loss: 0.0011, Val Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:12:52,549] Trial 13 finished with value: 0.0008512251570796399 and parameters: {'rnn_units': 128, 'dropout_rate_rnn': 0.4, 'dense_units': 56, 'dropout_rate_dense': 0.2, 'learning_rate': 0.01, 'weight_decay': 1e-05}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], Train Loss: 0.0119, Val Loss: 0.0047\n",
      "Early stopping nach 10 Epochen.\n",
      "Epoch [3/15], Train Loss: 0.0016, Val Loss: 0.0008\n",
      "Epoch [11/15], Train Loss: 0.0019, Val Loss: 0.0013\n",
      "Epoch [13/15], Train Loss: 0.0018, Val Loss: 0.0008\n",
      "Epoch [8/15], Train Loss: 0.0010, Val Loss: 0.0008\n",
      "Epoch [8/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [11/15], Train Loss: 0.0035, Val Loss: 0.0011\n",
      "Epoch [11/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [1/15], Train Loss: 0.0038, Val Loss: 0.0013\n",
      "Epoch [12/15], Train Loss: 0.0018, Val Loss: 0.0013\n",
      "Epoch [14/15], Train Loss: 0.0017, Val Loss: 0.0009\n",
      "Epoch [4/15], Train Loss: 0.0013, Val Loss: 0.0007\n",
      "Epoch [9/15], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [9/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0031, Val Loss: 0.0012\n",
      "Epoch [2/15], Train Loss: 0.0017, Val Loss: 0.0008\n",
      "Epoch [13/15], Train Loss: 0.0018, Val Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:14:33,842] Trial 10 finished with value: 0.0008140040104814445 and parameters: {'rnn_units': 112, 'dropout_rate_rnn': 0.4, 'dense_units': 32, 'dropout_rate_dense': 0.1, 'learning_rate': 0.0001, 'weight_decay': 1e-05}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0016, Val Loss: 0.0008\n",
      "Epoch [5/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [10/15], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [10/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [13/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [13/15], Train Loss: 0.0028, Val Loss: 0.0011\n",
      "Epoch [3/15], Train Loss: 0.0013, Val Loss: 0.0010\n",
      "Epoch [14/15], Train Loss: 0.0017, Val Loss: 0.0012\n",
      "Epoch [1/15], Train Loss: 0.0044, Val Loss: 0.0019\n",
      "Epoch [6/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [11/15], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [11/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [14/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [14/15], Train Loss: 0.0025, Val Loss: 0.0011\n",
      "Epoch [4/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [2/15], Train Loss: 0.0019, Val Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:15:57,881] Trial 11 finished with value: 0.00097119541210451 and parameters: {'rnn_units': 80, 'dropout_rate_rnn': 0.2, 'dense_units': 32, 'dropout_rate_dense': 0.30000000000000004, 'learning_rate': 0.0001, 'weight_decay': 0.001}. Best is trial 6 with value: 0.0006140163812585431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0016, Val Loss: 0.0010\n",
      "Epoch [7/15], Train Loss: 0.0011, Val Loss: 0.0008\n",
      "Epoch [12/15], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0011, Val Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:16:21,318] Trial 15 finished with value: 0.0005903245406854342 and parameters: {'rnn_units': 80, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 40, 'dropout_rate_dense': 0.2, 'learning_rate': 0.001, 'weight_decay': 0.0001}. Best is trial 15 with value: 0.0005903245406854342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0011, Val Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:16:28,960] Trial 12 finished with value: 0.0010618649304829418 and parameters: {'rnn_units': 128, 'dropout_rate_rnn': 0.4, 'dense_units': 32, 'dropout_rate_dense': 0.30000000000000004, 'learning_rate': 0.0001, 'weight_decay': 1e-05}. Best is trial 15 with value: 0.0005903245406854342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0023, Val Loss: 0.0012\n",
      "Epoch [5/15], Train Loss: 0.0011, Val Loss: 0.0008\n",
      "Epoch [3/15], Train Loss: 0.0014, Val Loss: 0.0008\n",
      "Epoch [1/15], Train Loss: 0.0077, Val Loss: 0.0013\n",
      "Epoch [1/15], Train Loss: 0.0090, Val Loss: 0.0014\n",
      "Epoch [1/15], Train Loss: 0.0210, Val Loss: 0.0020\n",
      "Epoch [8/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [2/15], Train Loss: 0.0028, Val Loss: 0.0011\n",
      "Epoch [2/15], Train Loss: 0.0077, Val Loss: 0.0014\n",
      "Epoch [13/15], Train Loss: 0.0010, Val Loss: 0.0008\n",
      "Epoch [13/15], Train Loss: 0.0012, Val Loss: 0.0006\n",
      "Epoch [3/15], Train Loss: 0.0019, Val Loss: 0.0009\n",
      "Epoch [6/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [3/15], Train Loss: 0.0042, Val Loss: 0.0015\n",
      "Epoch [4/15], Train Loss: 0.0013, Val Loss: 0.0007\n",
      "Epoch [2/15], Train Loss: 0.0032, Val Loss: 0.0009\n",
      "Epoch [4/15], Train Loss: 0.0015, Val Loss: 0.0008\n",
      "Epoch [4/15], Train Loss: 0.0025, Val Loss: 0.0010\n",
      "Epoch [9/15], Train Loss: 0.0011, Val Loss: 0.0008\n",
      "Epoch [5/15], Train Loss: 0.0013, Val Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:18:13,775] Trial 18 finished with value: 0.0005743369560913115 and parameters: {'rnn_units': 128, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 16, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 1e-05}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15], Train Loss: 0.0010, Val Loss: 0.0006\n",
      "Early stopping nach 14 Epochen.\n",
      "Epoch [5/15], Train Loss: 0.0018, Val Loss: 0.0012\n",
      "Epoch [14/15], Train Loss: 0.0011, Val Loss: 0.0010\n",
      "Epoch [7/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [6/15], Train Loss: 0.0013, Val Loss: 0.0007\n",
      "Epoch [5/15], Train Loss: 0.0012, Val Loss: 0.0009\n",
      "Epoch [3/15], Train Loss: 0.0019, Val Loss: 0.0009\n",
      "Epoch [6/15], Train Loss: 0.0015, Val Loss: 0.0008\n",
      "Epoch [1/15], Train Loss: 0.0077, Val Loss: 0.0014\n",
      "Epoch [7/15], Train Loss: 0.0013, Val Loss: 0.0009\n",
      "Epoch [7/15], Train Loss: 0.0013, Val Loss: 0.0007\n",
      "Epoch [2/15], Train Loss: 0.0028, Val Loss: 0.0009\n",
      "Epoch [10/15], Train Loss: 0.0011, Val Loss: 0.0010\n",
      "Epoch [8/15], Train Loss: 0.0013, Val Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:19:18,698] Trial 19 finished with value: 0.0006143561339183268 and parameters: {'rnn_units': 128, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 8, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 1e-05}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [8/15], Train Loss: 0.0013, Val Loss: 0.0008\n",
      "Epoch [3/15], Train Loss: 0.0020, Val Loss: 0.0008\n",
      "Epoch [8/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [6/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [4/15], Train Loss: 0.0014, Val Loss: 0.0009\n",
      "Epoch [9/15], Train Loss: 0.0013, Val Loss: 0.0006\n",
      "Epoch [1/15], Train Loss: 0.0049, Val Loss: 0.0017\n",
      "Epoch [9/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [4/15], Train Loss: 0.0016, Val Loss: 0.0007\n",
      "Epoch [11/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [10/15], Train Loss: 0.0013, Val Loss: 0.0006\n",
      "Epoch [2/15], Train Loss: 0.0020, Val Loss: 0.0009\n",
      "Epoch [10/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [5/15], Train Loss: 0.0013, Val Loss: 0.0011\n",
      "Epoch [9/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [11/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [3/15], Train Loss: 0.0015, Val Loss: 0.0008\n",
      "Epoch [7/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [5/15], Train Loss: 0.0013, Val Loss: 0.0008\n",
      "Epoch [11/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [6/15], Train Loss: 0.0012, Val Loss: 0.0006\n",
      "Epoch [12/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [4/15], Train Loss: 0.0013, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0012, Val Loss: 0.0006\n",
      "Epoch [7/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0011, Val Loss: 0.0010\n",
      "Epoch [13/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [5/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [13/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [8/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [10/15], Train Loss: 0.0011, Val Loss: 0.0008\n",
      "Epoch [8/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [6/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [14/15], Train Loss: 0.0012, Val Loss: 0.0006\n",
      "Epoch [6/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [14/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [9/15], Train Loss: 0.0011, Val Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:22:34,738] Trial 20 finished with value: 0.0006809995961262875 and parameters: {'rnn_units': 128, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 24, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.0001}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15], Train Loss: 0.0011, Val Loss: 0.0009\n",
      "Early stopping nach 13 Epochen.\n",
      "Epoch [15/15], Train Loss: 0.0012, Val Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:22:35,208] Trial 24 finished with value: 0.0006371874569595093 and parameters: {'rnn_units': 64, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 8, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.0001}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], Train Loss: 0.0011, Val Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:22:44,231] Trial 25 finished with value: 0.0006435765079063017 and parameters: {'rnn_units': 64, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 8, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.0001}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [10/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [9/15], Train Loss: 0.0013, Val Loss: 0.0009\n",
      "Epoch [7/15], Train Loss: 0.0012, Val Loss: 0.0009\n",
      "Epoch [11/15], Train Loss: 0.0011, Val Loss: 0.0008\n",
      "Epoch [8/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [11/15], Train Loss: 0.0011, Val Loss: 0.0009\n",
      "Epoch [9/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [1/15], Train Loss: 0.0118, Val Loss: 0.0012\n",
      "Epoch [1/15], Train Loss: 0.0094, Val Loss: 0.0012\n",
      "Epoch [12/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [10/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [10/15], Train Loss: 0.0012, Val Loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:23:47,448] Trial 26 finished with value: 0.0006287034429401354 and parameters: {'rnn_units': 64, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 24, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.0001}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15], Train Loss: 0.0011, Val Loss: 0.0008\n",
      "Early stopping nach 13 Epochen.\n",
      "Epoch [8/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [12/15], Train Loss: 0.0011, Val Loss: 0.0008\n",
      "Epoch [11/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [2/15], Train Loss: 0.0045, Val Loss: 0.0011\n",
      "Epoch [2/15], Train Loss: 0.0036, Val Loss: 0.0009\n",
      "Epoch [12/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [11/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [9/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [13/15], Train Loss: 0.0011, Val Loss: 0.0008\n",
      "Epoch [13/15], Train Loss: 0.0011, Val Loss: 0.0010\n",
      "Epoch [3/15], Train Loss: 0.0029, Val Loss: 0.0011\n",
      "Epoch [14/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [3/15], Train Loss: 0.0023, Val Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:24:56,299] Trial 27 finished with value: 0.0006295986669659126 and parameters: {'rnn_units': 64, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 24, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.0001}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0011, Val Loss: 0.0008\n",
      "Early stopping nach 15 Epochen.\n",
      "Epoch [12/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [10/15], Train Loss: 0.0012, Val Loss: 0.0008\n",
      "Epoch [14/15], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [4/15], Train Loss: 0.0020, Val Loss: 0.0008\n",
      "Epoch [4/15], Train Loss: 0.0016, Val Loss: 0.0007\n",
      "Epoch [13/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [11/15], Train Loss: 0.0012, Val Loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:25:28,908] Trial 21 finished with value: 0.0006421912859819244 and parameters: {'rnn_units': 96, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 24, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.0001}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [5/15], Train Loss: 0.0015, Val Loss: 0.0007\n",
      "Epoch [5/15], Train Loss: 0.0013, Val Loss: 0.0009\n",
      "Epoch [14/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [6/15], Train Loss: 0.0013, Val Loss: 0.0008\n",
      "Epoch [6/15], Train Loss: 0.0012, Val Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:26:06,871] Trial 22 finished with value: 0.000631184100242418 and parameters: {'rnn_units': 96, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 8, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.0001}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0012, Val Loss: 0.0006\n",
      "Epoch [13/15], Train Loss: 0.0012, Val Loss: 0.0009\n",
      "Epoch [7/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [7/15], Train Loss: 0.0011, Val Loss: 0.0006\n",
      "Epoch [14/15], Train Loss: 0.0012, Val Loss: 0.0006\n",
      "Epoch [8/15], Train Loss: 0.0011, Val Loss: 0.0012\n",
      "Epoch [8/15], Train Loss: 0.0011, Val Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:26:39,356] Trial 23 finished with value: 0.000626548415311845 and parameters: {'rnn_units': 96, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 8, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 0.0001}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0012, Val Loss: 0.0007\n",
      "Epoch [9/15], Train Loss: 0.0010, Val Loss: 0.0006\n",
      "Epoch [9/15], Train Loss: 0.0010, Val Loss: 0.0008\n",
      "Epoch [10/15], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [10/15], Train Loss: 0.0010, Val Loss: 0.0006\n",
      "Epoch [11/15], Train Loss: 0.0010, Val Loss: 0.0008\n",
      "Epoch [11/15], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [12/15], Train Loss: 0.0010, Val Loss: 0.0008\n",
      "Epoch [12/15], Train Loss: 0.0010, Val Loss: 0.0006\n",
      "Epoch [13/15], Train Loss: 0.0010, Val Loss: 0.0009\n",
      "Epoch [13/15], Train Loss: 0.0010, Val Loss: 0.0006\n",
      "Epoch [14/15], Train Loss: 0.0010, Val Loss: 0.0006\n",
      "Epoch [14/15], Train Loss: 0.0010, Val Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:27:50,906] Trial 29 finished with value: 0.0005941036032445188 and parameters: {'rnn_units': 96, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 16, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 1e-05}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0010, Val Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 13:27:51,215] Trial 28 finished with value: 0.0005934571509574345 and parameters: {'rnn_units': 96, 'dropout_rate_rnn': 0.30000000000000004, 'dense_units': 16, 'dropout_rate_dense': 0.1, 'learning_rate': 0.001, 'weight_decay': 1e-05}. Best is trial 18 with value: 0.0005743369560913115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Best trial parameters:\n",
      "rnn_units: 128\n",
      "dropout_rate_rnn: 0.30000000000000004\n",
      "dense_units: 16\n",
      "dropout_rate_dense: 0.1\n",
      "learning_rate: 0.001\n",
      "weight_decay: 1e-05\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    hp = {\n",
    "        'rnn_units': trial.suggest_int('rnn_units', 16, 128, step=16),\n",
    "        'dropout_rate_rnn': trial.suggest_float('dropout_rate_rnn', 0.1, 0.5, step=0.1),\n",
    "        'dense_units': trial.suggest_int('dense_units', 8, 64, step=8),\n",
    "        'dropout_rate_dense': trial.suggest_float('dropout_rate_dense', 0.0, 0.4, step=0.1),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [1e-2, 1e-3, 1e-4]),\n",
    "        'weight_decay': trial.suggest_categorical('weight_decay', [1e-5, 1e-4, 1e-3]),\n",
    "    }\n",
    "\n",
    "    rnn_model = SimpleRNN(input_size = X_train.shape[2], hp= hp)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(rnn_model.parameters(), lr=hp['learning_rate'], weight_decay=hp['weight_decay'])\n",
    "\n",
    "    num_epochs = 15\n",
    "    patience = 7  # Stop, wenn val_loss sich 10 Epochen lang nicht verbessert\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        rnn_model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        # Training Loop\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            y_pred = rnn_model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation Loop (nach jeder Epoche)\n",
    "        rnn_model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                y_pred = rnn_model(X_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Early Stopping Check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stopping_counter = 0  # Reset Counter\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Early stopping nach {epoch+1} Epochen.\")\n",
    "                break\n",
    "\n",
    "    return best_val_loss  # Val Loss zurückgeben für Optuna\n",
    "\n",
    "# Hyperparameter tuning\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30, n_jobs = 8)\n",
    "\n",
    "# Show Best Result\n",
    "print(\"Best trial parameters:\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best hyperparameters\n",
    "best_hp = study.best_trial.params\n",
    "with open(\"best_hp_all_models/best_hp_rnn.json\", \"w\") as f:\n",
    "    json.dump(best_hp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best hyperparameters \n",
    "with open(\"best_hp_all_models/best_hp_rnn.json\", \"r\") as f:\n",
    "    best_hp = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.0036, Val Loss: 0.0017\n",
      "Epoch [2/50], Train Loss: 0.0016, Val Loss: 0.0007\n",
      "Epoch [3/50], Train Loss: 0.0013, Val Loss: 0.0006\n",
      "Epoch [4/50], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [5/50], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [6/50], Train Loss: 0.0011, Val Loss: 0.0007\n",
      "Epoch [7/50], Train Loss: 0.0010, Val Loss: 0.0006\n",
      "Epoch [8/50], Train Loss: 0.0010, Val Loss: 0.0006\n",
      "Epoch [9/50], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [10/50], Train Loss: 0.0010, Val Loss: 0.0008\n",
      "Epoch [11/50], Train Loss: 0.0010, Val Loss: 0.0006\n",
      "Epoch [12/50], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [13/50], Train Loss: 0.0010, Val Loss: 0.0008\n",
      "Epoch [14/50], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [15/50], Train Loss: 0.0010, Val Loss: 0.0008\n",
      "Epoch [16/50], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Epoch [17/50], Train Loss: 0.0010, Val Loss: 0.0007\n",
      "Early stopping nach 17 Epochen.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bestes Modell mit den gefundenen Hyperparametern trainieren\n",
    "best_hp = study.best_trial.params\n",
    "final_model = SimpleRNN(input_size=X_train.shape[2], hp=best_hp)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=best_hp['learning_rate'], weight_decay=best_hp['weight_decay'])\n",
    "\n",
    "num_epochs = 50\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "patience = 10\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    final_model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = final_model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_history.append(train_loss)\n",
    "\n",
    "    # Validation Loss berechnen\n",
    "    final_model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            y_pred = final_model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    val_loss_history.append(val_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0  # Reset Counter\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f\"Early stopping nach {epoch+1} Epochen.\")\n",
    "            break\n",
    "\n",
    "    # Save weights of the model \n",
    "    torch.save(final_model.state_dict(), \"saved_models/rnn_model_final.pth\")\n",
    "\n",
    "# **Trainingshistorie plotten**\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss_history, label=\"Train Loss\")\n",
    "plt.plot(val_loss_history, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epochen\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Trainings- und Validierungsverlust\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleRNN(\n",
       "  (rnn): RNN(17, 112, batch_first=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=112, out_features=64, bias=True)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained model  \n",
    "rnn_final = SimpleRNN(input_size=X_train.shape[2], hp=best_hp)\n",
    "rnn_final.load_state_dict(torch.load(\"saved_models/rnn_model_final.pth\"))\n",
    "rnn_final.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m X_test_batch \u001b[38;5;241m=\u001b[39m X_test_batch\n\u001b[1;32m     12\u001b[0m y_test_batch \u001b[38;5;241m=\u001b[39m y_test_batch\n\u001b[0;32m---> 14\u001b[0m test_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(X_test_batch)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(test_outputs, y_test_batch\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[1;32m     16\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "rnn_final.eval()\n",
    "test_loss = 0\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_test_batch, y_test_batch in test_loader:\n",
    "        X_test_batch = X_test_batch\n",
    "        y_test_batch = y_test_batch\n",
    "\n",
    "        test_outputs = model(X_test_batch).squeeze()\n",
    "        loss = criterion(test_outputs, y_test_batch.squeeze())\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        test_predictions.extend(test_outputs.cpu().numpy())\n",
    "        test_targets.extend(y_test_batch.squeeze().cpu().numpy())\n",
    "\n",
    "# Mittelwert des Kriteriums (z. B. MSELoss)\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
    "\n",
    "# RMSE\n",
    "def RMSELoss(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "# Torch-Tensors\n",
    "y_pred_tensor = torch.tensor(test_predictions)\n",
    "y_true_tensor = torch.tensor(test_targets)\n",
    "\n",
    "rmse = RMSELoss(y_pred_tensor, y_true_tensor).item()\n",
    "print(f\"Test RMSE (PyTorch): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ep_forecasting_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
